\chapter{Learning Stable Periodic Robot Motions from Demonstration}
\label{chp:osmp}

\begin{foreword}
    This thesis has so far concentrated primarily on the use of learned models in shape sensing and control. However, a critical challenge in achieving fully autonomous robots lies in high-level decision-making. The controllers discussed in this work require either a setpoint or a trajectory to follow. In Chapter~\ref{chp:braincontrol}, we explored a method enabling users to guide the soft robot directly through their thoughts by manipulating setpoints in space, which a compliant impedance controller subsequently tracks. While this low-level \gls{HRI} provides precise control over the robot’s actions, it demands the user’s full attention and can become exhausting, thereby limiting the efficiency gains we expect to gain by introducing intelligent, autonomous robots.
    %
    An alternative approach involves the user specifying only high-level tasks, allowing the robot to plan its motions independently. Among potential methods, including \gls{RL} and optimization-based strategies like \gls{MPC}, \gls{LFD} stands out as particularly promising as it allows the learning of complex motions from humans or even from other biological creatures. As a special case of \gls{LFD}, research on learning motion policies using dynamical systems has been well-established~\citep {ijspeert2013dynamical}. Being referred to as \glsxtrfull{DMP} or \glsxtrfull{SMP}, this strategy exhibits interpretability, compliant behavior, and convergence guarantees. Recently, advances in deep learning and normalizing flows~\citep{kobyzev2020normalizing} have given rise to frameworks that increase the expressiveness of the motion policy by leveraging diffeomorphic mappings into latent spaces, parametrized by neural networks, combined with latent dynamical systems~\citep{rana2020euclideanizing, perez2023stable, zhi2024teaching}. These methods enable the learning of more complex behaviors while maintaining interpretability, stability, and convergence guarantees.
    %
    In this chapter, we extend this approach to learn periodic motions with guaranteed orbital stability. This is achieved by integrating a bijective encoder based on Euclideanizing flows with latent dynamics modeled as supercritical Hopf bifurcations. The approach aligns in terms of vision with the work in Chapter~\ref{chp:con}, but here, it is applied to motion policy rather than dynamical model learning.
\end{foreword}

\pagebreak

\begin{abstract}
    % As we aim to foster closer collaboration between humans and robots—or to have robots assist us in everyday tasks—it is essential that these machines exhibit behavior that is robust, compliant, and natural. 
    % Learning from demonstrations has proven to be a powerful approach for acquiring complex motion behaviors in a sample-efficient manner compared to methods like reinforcement learning.
    % However, many current techniques—such as state-of-the-art diffusion policies—still require a large number of demonstrations to cover most state-action pairs, as these models lack inherent convergence guarantees.
    % In contrast, dynamic motion primitives, which parameterize motion policies using dynamical systems, provide such convergence guarantees—often referred to as stable motion primitives—while maintaining natural and compliant behavior even under significant disturbances.
    % Recent efforts have focused on leveraging linear latent dynamics paired with a learned, bijective encoder to derive stable, point-to-point motion primitives from demonstrations. However, these methods have fallen short when it comes to encoding periodic motions. In this work, we demonstrate that employing supercritical Hopf bifurcations in latent space can effectively learn periodic motions from demonstrations while ensuring stability. We further introduce techniques such as phase synchronization, online shaping of the convergence behavior, and encoder conditioning, which empower us to address complex periodic robotic tasks like turtle swimming and surface cleaning. These advancements pave the way for collaborative robots to perform periodic motions accurately, compliantly, stably, and naturally—bringing us one step closer to safe and intuitive human-robot interaction.
    Learning from demonstration provides a sample-efficient approach to acquiring complex behaviors, enabling robots to move robustly, compliantly, and with fluidity. In this context, Dynamic Motion Primitives offer built-in stability and robustness to disturbances but often struggle to capture complex periodic behaviors. Moreover, they are limited in their ability to interpolate between different tasks. These shortcomings substantially narrow their applicability, excluding a wide class of practically meaningful tasks such as locomotion and rhythmic tool use.
    %
    In this work, we introduce \glspl{OSMP}—a framework that combines a learned diffeomorphic encoder with a supercritical Hopf bifurcation in latent space, enabling the accurate acquisition of periodic motions from demonstrations while ensuring formal guarantees of orbital stability and transverse contraction. Furthermore, by conditioning the bijective encoder on the task, we enable a single learned policy to represent multiple motion objectives, yielding consistent zero-shot generalization to unseen motion objectives within the training distribution.
    %
    We validate the proposed approach through extensive simulation and real-world experiments across a diverse range of robotic platforms—from collaborative arms and soft manipulators to a bio-inspired rigid–soft turtle robot—demonstrating its versatility and effectiveness in consistently outperforming state-of-the-art baselines such as diffusion policies, among others.
\end{abstract}

\blfootnote{This chapter is partly based on \faFileTextO ~\emph{\textbf{M. Stölzle}, T.K. Rusch*, Z.J. Patterson*, R. Pérez Dattari, F. Stella, J. Hughes, C. Della Santina, and D. Rus (2025). Learning to Move in Rhythm: Task-Conditioned Motion Policies with Orbital Stability Guarantees. In Science Robotics Special issue on Transfer Learning, Foundation Models, and Emerging Capabilities. 
\textbf{\emph{Under Review}}}~\citep{stolzle2025learning}.

T.K.R and Z.J.P contributed equally to this work.
M.S. conceived the project, and M.S., Z.J.P, T.K.R., C.D.S, and D.R. developed the research idea. 
M.S. developed the framework for training the orbital motion primitives.
M.S. and C.D.S derived the phase synchronization approach.
M.S. and T.K.R designed the encoder conditioning technique, and M.S. devised the smooth conditioning interpolation loss.
Z.J.P. and M.S. performed the turtle robot experiments; M.S. conducted the UR5 robotic manipulator experiments; R.P.D. and M.S. executed the KUKA cobot experiments; M.S. and F.S. carried out the Helix soft robot experiments. 
M.S., Z.J.P, T.K.R., R.P.D., and F.S. performed the data analysis.
M.S., Z.J.P, T.K.R., R.P.D., and F.S. wrote the manuscript. 
D.R., C.D.S, T.K.R, and Z.J.P supervised the research project. D.R., C.D.S, and J.H. provided funding.
}

%% Start the actual chapter on a new page.
\newpage

\input{osmp/sections/S01_introduction}
\input{osmp/sections/S02_methodology}
\input{osmp/sections/S03_results}
\input{osmp/sections/S04_discussion}
\input{osmp/sections/S05_conclusion}
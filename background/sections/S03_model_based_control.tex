\section{Model-Based Control}\label{sec:background:model_based_control}
% In this section, we review existing model-based controllers for soft robots whose control law is available in closed form.
% Many of these control approaches appear at various points throughout the thesis, such as the P-satI-D+potential shaping controller in Section~\ref{sec:hsacontrol:configuration_space_regulation} and Chapter~\ref{chp:pcsregression} \& \ref{chp:con}, the PD+ controller in a version additionally also considering the actuator dynamics via backstepping in Chapter~\ref{chp:backstepping} and the operational space impedance controller in Section~\ref{sec:hsacontrol:operational_space_impedance_control}.
% This section only contains a top-level discussion of the most common closed-form model-based control laws that have been developed for soft robots. For a more detailed discussion of the controllers, including stability proofs using Lyapunov arguments, we point the interested reader to the respective publications~\citep{della2020model, pustina2022feedback, pustina2022p, borja2022energy, della2023model}. For an in-depth study of the control of underactuated soft robots, we recommend \citet{pustina2025analysis}.
In this section, we review closed-form controllers for soft robots that can leverage advanced nonlinear models\footnote{Please note that this excludes approaches relying on linear/linearized models such as \gls{LQR} and that model-based controllers that are not available in closed-form, such as \gls{MPC}, are out of scope of this thesis.}. Many of these approaches appear throughout the thesis, such as the P-satI-D+potential shaping controller in Section~\ref{sec:hsacontrol:configuration_space_regulation} and Chapters~\ref{chp:pcsregression} and \ref{chp:con}, the PD+ controller—augmented with backstepping to consider actuator dynamics—in Chapter~\ref{chp:backstepping}, and the operational space impedance controller in Section~\ref{sec:hsacontrol:operational_space_impedance_control}. This section provides a high-level overview of the most common closed-form model-based control laws developed for soft robots. For a more detailed discussion of these controllers, including Lyapunov-based stability proofs, interested readers should consult the respective publications~\citep{della2020model, pustina2022feedback, pustina2022p, borja2022energy, della2023model}. For an in-depth study of controlling underactuated soft robots, we recommend \citet{pustina2025analysis}.

\textcolor{red}{TODO: \begin{itemize}
    \item Better organize and rename the section heading
    \item Add comment on why we state the controllers in actuation coordinates. Clearly state the limitations of this, such as the lack of mapping into actuation coordinates for some actuation matrices, the possible stability issues, and the lack of experimental verification.
    \item actuated rows of EOM matrices
    \item verify controllers with trajectory tracking paper from Rizello's group
\end{itemize}}

\subsection{Preliminaries}
% For simplicity, we refer in the following to the fully actuated case and specifically the case of an identified actuation matrix $A = \mathbb{I}_n$.
% For an extended discussion on the control in the underactuated setting (i.e., $m < n$), we refer the interested reader to \citet{pustina2025analysis}.

\subsubsection{Problem Statement}
% The literature on closed-form model-based controllers mostly considers two problem settings~\citep{sciavicco2012modelling}: \emph{setpoint regulation} and \emph{trajectory tracking}.
% Generally, a reference trajectory is defined with the tuple $(q^\mathrm{d}(t), \dot{q}^\mathrm{d}(t), \ddot{q}^\mathrm{d}(t))$ consisting of the desired configuration, configuration velocity, and configuration acceleration at the current time step.
% Now, we strive to design a \emph{trajectory tracking} controller that allows the soft robotic system to track the reference trajectory as accurately as possible while rejecting any disturbances that might act on the system.
% If we only care about the goal of a motion, we can simplify the problem to a \emph{setpoint regulation} scenario, where a controller regulates the system towards a desired configuration $q^\mathrm{d}$. In the setpoint regulation case, we simply set $\dot{q}^\mathrm{d} = 0$.
% Please note that such motion references, either setpoints or trajectories, can be not just specified in configuration space but given in a variety of coordinate frames. We will discuss this aspect further below in the subsection \emph{Coordinate Frames}.
The literature on closed-form model-based controllers generally considers two problem settings~\citep{sciavicco2012modelling}: \emph{setpoint regulation} and \emph{trajectory tracking}. Typically, a reference trajectory is represented by the tuple $(q^\mathrm{d}(t), \dot{q}^\mathrm{d}(t), \ddot{q}^\mathrm{d}(t))$, which comprises the desired configuration, velocity, and acceleration at each time step. For \emph{trajectory tracking}, our objective is to design a controller that enables the soft robotic system to follow the reference trajectory, and specifically its positional references, as precisely as possible while rejecting any disturbances
\begin{equation}
    \lim_{t \to \infty} = q^\mathrm{d}(t) - q(t) = 0_n.
\end{equation}
Please note that we typically require both $q^\mathrm{d}(t)$ and $\dot{q}^\mathrm{d}(t)$ to be bounded. Therefore, two positive constants $\gamma_q, \gamma_{\dot{q}} > 0$ need to exist such that~\citep{della2020model}
\begin{equation}
    \lVert q^\mathrm{d}(t) \rVert < \gamma_q,
    \qquad
    \lVert \dot{q}^\mathrm{d}(t) \rVert < \gamma_{\dot{q}}.
\end{equation}
Alternatively, if only the final goal of the motion is of interest, the problem can be simplified to a \emph{setpoint regulation} scenario, where the controller drives the system toward a desired configuration $q^\mathrm{d}$ (with $\dot{q}^\mathrm{d} = 0$).
Then, we would like to design a regulator that achieves the following asymptotic convergence
\begin{equation}
    \lim_{t \to \infty} = q^\mathrm{d} - q(t) = 0_n.
\end{equation}
Note that these motion references—whether setpoints or trajectories—can be specified not only in configuration space but also in various coordinate frames, a topic we discuss further in the subsection \emph{Coordinate Frames}.

\subsubsection{Control Design Objectives}
% When we devise a model-based controller, we usually pursue several, possibly competing, goals. In the following section, we will detail a selection of these criteria, making it possible to compare the tradeoffs between various model-based controllers.
When designing a model-based controller, we often balance several, sometimes conflicting, objectives. The following section outlines a selection of these criteria, enabling a comparison of the tradeoffs between various model-based controllers.

\begin{itemize}
    \item \textbf{Control Frequency/Computational Complexity/.} 
    % In this thesis, we strive for the control law to be available in closed form, which significantly increases the computational efficiency compared to, for example, optimization-based approaches and allows for higher control frequencies, which improves performance and reduces the risk of instability for feedback controllers. When a closed-form control law is available, the computational complexity comes down to (a) the model complexity and (b) which terms of the models need to be evaluated for the controller. For example, a potential shaping controller only requiring access to the potential forces is computationally more efficient than a computed torque controller that requires evaluation of all dynamical matrices within the \glspl{EOM}. 
    In this thesis, we aim to derive a control law in closed form, which greatly enhances computational efficiency compared to, for example, optimization-based methods and supports higher control frequencies. This improvement not only boosts performance but also reduces the risk of instability in feedback controllers. When a closed-form control law is available, the computational complexity is determined by (a) the complexity of the model and (b) the specific model terms that must be evaluated for the controller. For instance, a potential shaping controller, which requires only knowledge about the potential forces, is computationally more efficient than a computed torque controller that necessitates evaluating all the dynamical matrices within the \glspl{EOM}.
    % \item \textbf{Stability.} Generally, we strive for exponential global asymptotic stability of the closed-loop system. This is best illustrated in the setpoint regulation scenarios, where we strive for it to converge to a given setpoint. In the case of \gls{GAS}, no matter with which state the system is initialized, it will always converge to the setpoint with an exponential rate of convergence~\citep{khalil2002nonlinear}. If exponential convergence is not possible, we strive for asymptotic stability, which still guarantees convergence but while losing lower bounds on the rate of convergence rates. In case the controller is not able to achieve \gls{GAS}, we at least strive to guarantee local asymptotic stability around the setpoint. This means that when the system state is initialized within a region of attraction around the setpoint, it will stabilize the system around this local attractive equilibrium of the system, and the system will converge to this setpoint. However, the system might exhibit other stable or unstable equilibria, which means that if the system is initialized outside the region of attraction of the setpoint, it will (likely) not converge.
    \item \textbf{Stability.}  Our goal is generally to achieve exponential \gls{GAS} of the closed-loop system. This is best demonstrated in setpoint regulation scenarios, where the system should converge to a specified setpoint regardless of its initial state and do so at an exponential rate~\citep{khalil2002nonlinear}. If exponential convergence is unattainable, we still aim for asymptotic stability, which ensures convergence but without a guaranteed rate. At a minimum, we require local asymptotic stability around the setpoint, meaning that if the system state starts within a certain region of attraction, it will stabilize at the setpoint. However, if initialized outside this region, the system may not converge due to the presence of other stable or unstable equilibria.
    \item \textbf{Control Effort.} 
    % To enable more energy-efficient (mobile) robots, we strive to reduce the power consumed by the actuator, consisting of the applied force/torque $\tau$ and the associated actuator velocity $\dot{\mu}$. As the required steady-state force is usually fixed by the soft robot design \& the given task, we mainly focus on reducing the control effort\footnote{In optimal control, this can be accomplished by adding a regularization term on the control input $\tau$ to the cost function.} - which is usually defined as the rate of change of $\tau$ over time, and with that, reduces the needed actuator velocity $\dot{\mu}$ and the consumed power.
    To facilitate energy-efficient (mobile) robots, we strive to minimize the power consumed by the actuators, which includes both the applied force/torque $\tau$ and the corresponding actuator velocity $\dot{\mu}$. Since the necessary steady-state force is typically determined by the soft robot’s design and the task at hand, our focus is on reducing the control effort—often defined as the rate of change of $\tau$ over time—which in turn reduces the required actuator velocity and overall power consumption.
    \item \textbf{Compliance.} 
    % For augmenting the mechanical compliance of soft robots, we strive for the controller also to exhibit compliant behavior. Specifically, this means that the feedback controller should exhibit as low as possible integral gains as they reduce the stability margins and can cause safety issues, and low proportional feedback gains as they increase the stiffness of the closed-loop system - which makes the soft robot body less soft than desired.
    To complement the inherent mechanical compliance of soft robots, the controller should also be compliant. This means designing feedback controllers with minimal integral gains to avoid compromising stability margins and potential safety issues, as well as using low proportional feedback gains to prevent increasing the closed-loop stiffness—ensuring the robot retains its desired softness.
    \item \textbf{Robustness.} 
    % Model-based controllers exploit our knowledge about the system behavior to design smart feedback and feedforward terms and modulate the dynamics of the closed-loop system in such a way that they make control easier. However, in reality, as said beautifully by \citet{box1976science}, "All models are wrong." controllers that assume perfect model knowledge to cancel out all or most of the existing system dynamics, as one based on feedback linearization are very sensitive to modeling errors. The reason for that is that when the modeled dynamics are canceled out, the unmodelled dynamics can quickly dominate the shaped dynamics (e.g., the linear dynamics), possibly inducing instability and leading to bad system performance. On the other hand, pure model-based feedforward controllers that do not depend on the current system state are often more robust to modeling errors as they reshape the system dynamics instead of fully \emph{deleting} it and trying to reconstruct it from scratch.
    Model-based controllers leverage our understanding of system behavior to craft intelligent feedback and feedforward components that simplify control. However, as \citet{box1976science} aptly noted, “All models are wrong.” Controllers that rely on perfect model knowledge to cancel out most of the system dynamics, such as those based on feedback linearization, are highly sensitive to modeling errors. When the modeled dynamics are canceled, any unmodeled dynamics can quickly dominate, potentially inducing instability and poor performance. In contrast, purely model-based feedforward controllers—which do not depend on the current system state—tend to be more robust to modeling errors, as they reshape rather than entirely eliminate the open-loop system dynamics.
\end{itemize}

\subsubsection{Coordinate Frames}
% In the following, we will introduce several coordinate frames in which control laws can be designed and we lay out the advantages and drawbacks of each strategy.
In the following section, we introduce several coordinate frames for designing control laws and outline the advantages and disadvantages of each approach.

\paragraph{Control in Configuration Space.}
% As introduced in Sec.~\ref{sec:background:kinematics}, the configuration space is usually defined as the kinematic variables parametrizing the backbone shape of the soft robot. Therefore, control in configuration space is also referred to as \emph{shape control}. The advantage of devising a controller in configuration space is that naturally, the robot dynamics are also defined here (see Eq.~\ref{eq:background:dynamics:eom}), which makes the controller law derivation usually simpler and easier to prove stability. Disadvantages include that (a) it can be challenging to come up with a (consistent) reference in configuration space as the actual important motion is usually defined in operational space and, in particular in underactuated settings, not all configurations can actually be (statically) achieved by the actuators~\citep{della2025pushing}, and (b) the mapping of control inputs defined as generalized torques into an actuation $\tau$ can be challenging - specifically when $A(q)$ exhibits singularities or again, when the soft robot is underactuated, which requires special controllers~\citep{pustina2022feedback}.
As introduced in Sec.\ref{sec:background:kinematics}, the configuration space is typically defined by the kinematic variables that parameterize the soft robot’s backbone shape, which is why control in this space is often referred to as \emph{shape control}. One advantage of designing a controller in configuration space is that the robot dynamics are naturally defined here (see Eq.\ref{eq:background:dynamics:eom}), making it simpler to derive the control law and prove its stability. However, there are disadvantages: (a) establishing a consistent reference in configuration space can be challenging since the key motion is often specified in operational space, and in underactuated settings, not all configurations can be statically achieved by the actuators~\citep{della2025pushing}; and (b) mapping control inputs defined as generalized torques into an actuation $\tau$ can be difficult—especially when $A(q)$ exhibits singularities or when the soft robot is underactuated, which requires specialized controllers~\citep{pustina2022feedback}.


\paragraph{Control in Actuation Space.}
% To overcome the previously mentioned difficulties of mapping generalized torques into actuator signals, we can leverage the collocated dynamics~\citep{pustina2024input} presented in Sec.~\ref{sub:background:dynamics:actuation_space} to devise controllers directly in actuation space. Even in the underactuated setting, the first $m$ actuation coordinates $\varphi_\mathrm{a}$ are all directly forced by $\tau$ through an identity actuation matrix, making the derivation of controllers much easier.
% In practice, a configuration-space reference $(q^\mathrm{d},\dot{q}^\mathrm{d})$ can be transformed into an actuation-space referenced through 
To address the challenges of mapping generalized torques into actuator signals, we can exploit the collocated dynamics~\citep{pustina2024input} presented in Sec.~\ref{sub:background:dynamics:actuation_space} to design controllers directly in actuation space. Even in underactuated scenarios, the first $m$ actuation coordinates $\varphi_\mathrm{a}$ are directly influenced by $\tau$ through an identity actuation matrix, significantly simplifying the derivation of controllers. In practice, a configuration-space reference $(q^\mathrm{d},\dot{q}^\mathrm{d})$ can be transformed into an actuation-space reference using
\begin{equation}
    \varphi^\mathrm{d} = h(q^\mathrm{d}),
    \qquad
    \dot{\varphi}^\mathrm{d} = J_\mathrm{h}(q^\mathrm{d}) \, \dot{q},
    \qquad
    \ddot{\varphi}^\mathrm{d} = J_\mathrm{h}(q^\mathrm{d}) \, \ddot{q}^\mathrm{d} + \dot{J}_\mathrm{h}(q^\mathrm{d}) \, \dot{q}^\mathrm{d}.
\end{equation}
% In addition to the simple mapping of control inputs into an actuation $\tau$, we can also easily enforce actuator limits.
% Similar to the case of control in configuration space, a challenge can be to devise a consistent actuation-space reference.
This approach not only simplifies the mapping of control inputs into an actuation $\tau$ but also makes it easier to enforce actuator limits. Nevertheless, devising a consistent actuation-space reference, specifically one that is statically or dynamically feasible, remains a challenge.

\paragraph{Control in Operational Space.}
% Here, the dynamics defined in Eq.~\ref{eq:background:dynamics:eom_task_space} are leveraged to directly devise a controller in operational space~\citep{khatib1987unified}, where the dimensionality $o$ of the operational space reference (generally) needs to fulfill the condition $o \leq n$.
% Specifically, operational space impedance controllers are popular as they allow the specification of operational space stiffness, which is directly relevant to robot-environment interactions. Furthermore, as the reference is usually directly given in operational space, no complex inverse kinematics routine is necessary.
% Disadvantages include the lack of formal stability guarantees, specifically with respect to the null-space dynamics, and the integration of actuator limits being much more challenging.
In this setting, we use the dynamics defined in Eq.\ref{eq:background:dynamics:eom_task_space} to directly design a controller in operational space~\citep{khatib1987unified}. Typically, the operational space reference’s dimensionality $o$ must satisfy $o \leq n$. Operational space impedance controllers are particularly popular because they allow for direct specification of operational space stiffness and damping characteristics, which is crucial for robot-environment interactions. Additionally, since the reference is provided directly in operational space, complex inverse kinematics routines are unnecessary. However, disadvantages include the lack of formal stability guarantees—especially regarding the null-space dynamics—and the greater difficulty in considering actuator limits.

% In the following sections, we will generally define the control law as a function of the robot configuration $q$ and its time derivative $\dot{q}$ as the mapping into operational space through the forward kinematics $\chi = \pi(q,s)$ or into actuation coordinates through $\varphi = h(q)$ is usually always possible if needed. The same applies to the control reference, as discussed in the next paragraph.
In the following sections, we will generally define the control law as a function of the robot configuration $q$ and its time derivative $\dot{q}$, since mapping into operational space via the forward kinematics $\chi = \pi(q,s)$ or into actuation coordinates through $\varphi = h(q)$ is usually straightforward if needed. The same applies to the control reference, as discussed in the next paragraph.

\subsubsection{Taxonomy of Control Terms}
% Most controllers that we consider in this thesis can be separated into a feedforward term that leverages model knowledge and a pure feedback term. 
% Specifically, a control law $\tau(t, q, \dot{q})$ can be decomposed into
Most controllers considered in this thesis consist of two components: either (a) a pure feedforward or mixed feedforward-feedback term that leverages model knowledge and (b) a pure feedback term. Specifically, a control law $\tau(t, q, \dot{q})$ can be decomposed into
\begin{equation}
    \tau(t, q, \dot{q}) = \underbrace{\tau_\mathrm{mb}(t, q, \dot{q})}_\text{Model-Based} + \underbrace{\tau_\mathrm{fb}(t, q, \dot{q})}_\text{Pure Feedback},
\end{equation}
% where $\tau_\mathrm{mb}(t, q, \dot{q}): \mathbb{R} \times \mathbb{R}^n \times \mathbb{R}^n \to \mathbb{R}^m$ is a model-based, not necessarily pure\footnote{A pure feedforward term would have the functional signature $\tau(t)$ as it only depends on the time-based reference $(q^\mathrm{d},\dot{q}^\mathrm{d})$ but not the current soft robot state $(q,\dot{q})$.}, feedforward term and $\tau_\mathrm{fb}(t, q, \dot{q})$ is a pure feedback term as it does not integrate any model knowledge.
Here, $\tau_\mathrm{mb}(t, q, \dot{q}): \mathbb{R} \times \mathbb{R}^n \times \mathbb{R}^n \to \mathbb{R}^m$ denotes a model-based term—not necessarily a pure feedforward\footnote{A purely feedforward term would have the signature $\tau(t)$, as it depends solely on the time-based reference $(q^\mathrm{d},\dot{q}^\mathrm{d})$ rather than the current soft robot state $(q,\dot{q})$.}—while $\tau_\mathrm{fb}(t, q, \dot{q})$ is a pure feedback term that does not incorporate any model knowledge.

\textcolor{red}{In the following sections, we prepare various options for model-based feedforward terms and pure feedback terms that can be mostly freely combined. Lastly, }

\subsection{Pure Feedback Terms}\label{sub:background:model_based_control:feedback_terms}
In this thesis, we consider the following formulation for a pure feedback controller
\begin{equation}
    \tau_\mathrm{fb} = K_\mathrm{p} \left (\varphi_\mathrm{a}^\mathrm{d}(t) - \varphi_\mathrm{a}(t) \right ) + K_\mathrm{d} \left ( \dot{\varphi}_\mathrm{a}^\mathrm{d}(t) - \dot{\varphi}_\mathrm{a}(t) \right ) + K_\mathrm{i} \int_0^t \sigma \left ( \varphi_{\mathrm{a}}^\mathrm{d}(t')-\varphi_{\mathrm{a}}(t') \right ) \: \mathrm{d} t',
\end{equation}
where $K_\mathrm{p}, K_\mathrm{p}, K_\mathrm{d} \in \mathbb{R}^{m \times m}$ are control gain matrices, which we usually choose to be diagonal. $\sigma(r): \mathbb{R}^m \to \mathbb{R}^m$ is a function to transform the control error $\varphi_{\mathrm{a}}^\mathrm{d}(t)-\varphi_{\mathrm{a}}(t)$ before integrating it.
Based on this general formulation, we can devise several specific versions, which we introduce below.

\paragraph{PID Control.} A traditional PID controller can be easily recovered by setting the saturation function as the identity: $\sigma(r) = r$. We have considered such a feedback controller as a baseline in Chapters~\ref{chp:hsacontrol} \& \ref{chp:backstepping}.

\paragraph{PD Control.} A PD+~\citep{kelly1997pd}, as often used for the low-level control of rigid robots, can be realized by combining a PD controller with a compensation of static forces. The PD feedback term is simply implemented by choosing $K_\mathrm{i} = 0$.

\paragraph{P-satI-D Control.} \citet{pustina2022p} has proposed an integral-saturated PID for shape regulation of soft robots via feedback control. A common choice for the saturated function is $\sigma(r) = \tanh(\gamma \, r)$, where $\gamma \in \mathbb{R}_+$ is a control gain to compress the control error before saturating it. We leverage this integral-saturated PID in Section~\ref{sec:hsacontrol:configuration_space_regulation} and Chapters~\ref{chp:pcsregression} \& \ref{chp:con}.

\subsection{Model-Based Terms: The Fully Actuated Case}\label{sub:background:model_based_control:model_based_terms_fully_actuated}
Please note that for all controllers we introduce below, we assume that (1) the model is accurate or alternatively sufficiently large feedback gains are chosen (see high-gain control~\citep{marino1985high}), and (2) the integrability condition~\citep{pustina2024input} and mapping into actuation coordinates can be identified.
Furthermore, (3) we assume here for the square matrix $A(q) \in \mathbb{R}^{n \times n}$ to be invertible for any $q \in \mathbb{R}^n$ or at least in the relevant workspace.
For the setpoint regulators, we additionally assume that (4) the setpoint $q^\mathrm{q}/\varphi^\mathrm{q}$ is an attainable equilibrium of the underactuated system~\citep{pustina2022feedback} - which means that it fulfills the property
\begin{equation}
    G(q^\mathrm{d}) + K(q^\mathrm{q}) = A(q^\mathrm{q}) \, \tau^\mathrm{ss},
\end{equation}
for a constant control action $\tau^\mathrm{ss}$, 
% (4) the system is within the region of attraction of the setpoint which can always be globally accomplished in scenarios where the potential field is convex - i.e., when
(5) The system must be initialized within the setpoint’s region of attraction. This condition can be globally ensured when the potential field is convex—i.e., when
\begin{equation}
    \frac{\partial^2 \mathcal{U}(q)}{\partial q^2} \succ 0 \quad \forall q \in \mathbb{R}^n
\end{equation}
% - or by employing (partial) feedback linearization, or often by increasing the feedback gains, and with that, increasing the stiffness of the system,
% and (5) that the actuator is sufficiently fast at tracking its reference $(\mu^\mathrm{d}, \mu^\mathrm{d})$ such that we can approximate $\tau^\mathrm{d} \approx = \tau(\mu,\dot{\mu})$, where $\tau^\mathrm{d}$ is the desired actuation/control input and $\tau(\mu,\dot{\mu})$ are the actually generated forces/torques/currents/pneumatic pressure.
—or by applying (partial) feedback linearization, or often by increasing the feedback gains, thereby enhancing the system’s stiffness~\citep{della2017controlling, della2023model}. (6) Additionally, the actuator needs to be fast enough in tracking its reference $(\mu^\mathrm{d}, \mu^\mathrm{d})$ so that we can approximate $\tau^\mathrm{d} \approx \tau(\mu,\dot{\mu})$, where $\tau^\mathrm{d}$ denotes the desired actuation/control input and $\tau(\mu,\dot{\mu})$ represents the actual forces, torques, currents, or pneumatic pressure generated.

Finally, many of these controllers formulated in actuation coordinates have not been tested in simulation, and most have not yet been experimentally verified as the mapping into actuation coordinates was only very recently proposed~\citep{pustina2024input}.

We remind that in the case of full actuation, we have $n = m$.

\subsubsection{Setpoint Regulation with Feedforward Compensation}
\textcolor{red}{TODO: cite }
The following pure feedforward term regulates the system towards the setpoint $\varphi^\mathrm{d} = h(q^\mathrm{d})$ in actuation coordinates~\citep{kelly1994pd, borja2022energy, della2023model, pustina2025analysis}
\begin{equation}\label{eq:background:model_based_control:fully_actuated:potential_shaping_regulation}
    \tau_\mathrm{mb} = \partial_{\varphi} \mathcal{U}_\varphi(\varphi^\mathrm{d})  = A^{-1}(q^\mathrm{d}) \left ( G(q^\mathrm{d}) + K(q^\mathrm{d}) \right ).
\end{equation}
We note that as the term is pure feedforward, the control input $\tau_\mathrm{mb}$ is constant.
% It can be seen how the constant model-based control input $\tau_\mathrm{mb}$ is a pure feedforward term.
Oftentimes, this pure feedforward term is complemented by a feedback controller that contains a PD-like term~\citep{della2023model}, e.g., $\tau_\mathrm{fb}(q,\dot{q}) = K_\mathrm{p} \left ( \varphi^\mathrm{d} - \varphi \right ) - K_\mathrm{d} \dot{\varphi}$, which renders the closed-loop dynamics to take the form
% This model-based feedforward term renders the closed-loop dynamics
\begin{equation}
    M_\varphi(q) \, \ddot{\varphi} + \eta_\varphi(q,\dot{q}) \, \dot{\varphi} + \partial_{\varphi} \mathcal{U}_\varphi(\varphi) - \partial_{\varphi} \mathcal{U}_\varphi(\varphi^\mathrm{d}) + K_\mathrm{p}  \left ( \varphi - \varphi^\mathrm{d} \right ) + \left ( D_\varphi(q) + K_\mathrm{d} \right ) \, \dot{\varphi} = 0_n.
\end{equation}
% to be locally asymptotically stable for a sufficiently large proportional feedback gain $K_\mathrm{p} > 0$.
As mentioned already before, for this regulator to be effective, $\varphi^\mathrm{d}$ needs to be an attainable equilibrium of the system.
\textcolor{red}{...}
This stability can be shown via the Lyapunov candidate~\citep{della2023model}
\begin{equation}
    V(q,
\end{equation}
which is a valid Lyapunov function - fulfilling the requirements $V(\varphi^\mathrm{d},0_n) = 0$ and $V(\varphi,\dot{\varphi}) > 0 \: \forall \: (\varphi, \dot{\varphi}) \in (\mathbb{R}^n, \mathbb{R}^n) \setminus \{ (\varphi^\mathrm{d}, 0_n) \}$ - if the closed-loop potential energy is local



In the following, we will discuss the convergence guarantees in more detail.

\textbf{Convex Potential Field.} If the potential field is convex (i.e., $\frac{\partial^2}{\partial \varphi^2}  \mathcal{U}_\varphi(\varphi) \succ 0 \: \forall \varphi \in \mathbb{R}$) this controller is globally asymptotically stable - even with a deactivated feedback term $\tau_\mathrm{fb}(t,q,\dot{q})=0$.

\textbf{Constant Actuation Matrix and Elastic Domination.} Another interesting case is the one of a constant actuation matrix $A(q) = A$ and elastic domination with $\frac{\partial K(q)}{\partial q} + $

 If this is not the case, the region of attraction can be increased, or the controller can even be made globally asymptotically stable by sufficiently increasing the proportional gains $K_\mathrm{p}$ of the feedback controller, which makes the system stiffer and more susceptible to instability because of measurement errors.

\subsubsection{Setpoint Regulation with Gravity Cancellation and Compensation of Elastic Forces}
In case the elastic potential is convex, but the gravitational potential renders the total potential energy to be non-convex, we can reduce the necessary (proportional) feedback gains, compared to the \emph{Setpoint Regulation with Feedforward Compensation} controller, by canceling instead of compensating the gravitational forces. The control law is then given as~\citep{della2020model}
\begin{equation}
    \tau_\mathrm{mb}(q) =  \underbrace{A^{-1}(q) \, G(q)}_\text{Cancel Gravity} + \underbrace{A^{-1}(q^\mathrm{d}) \, K(q^\mathrm{d})}_\text{Comp. Elasticity} \big )
\end{equation}
leading to the closed-loop dynamics
\begin{equation}
    M_\varphi(q) \, \ddot{\varphi} + \eta_\varphi(q,\dot{q}) \, \dot{\varphi} + A^{-1}(q) \,  K(q) - A^{-1}(q^\mathrm{d}) \, K(q^\mathrm{d}) + D_\varphi(q) \, \dot{\varphi} = \tau_\mathrm{fb}(t, q, \dot{q}),
\end{equation}
which we can rewrite, assuming that a PD term is part of the feedback as
\begin{equation}\footnotesize
    M_\varphi(q) \, \ddot{\varphi} + \eta_\varphi(q,\dot{q}) \, \dot{\varphi} + A^{-1}(h^{-1}(\varphi)) \,  K(h^{-1}(\varphi)) - A^{-1}(h^{-1}(\varphi^\mathrm{d})) \, K(h^{-1}(\varphi^\mathrm{d})) + K_\mathrm{p} \left ( \varphi-\varphi^\mathrm{d} \right ) + \left ( D_\varphi(q) + K_\mathrm{d} \right ) \, \dot{\varphi} = 0_n,
\end{equation}
which is asymptotically stable if the elastic potential $\mathcal{U}_{\varphi,\mathrm{K}}(\varphi)$ is locally or globally convex
\begin{equation}\label{eq:background:model_based_control:fully_actuated:regulation_gravity_cancellation:closed_loop_potential_convexity}
    \frac{\partial^2}{\partial \varphi^2} \mathcal{U}_{\varphi,\mathrm{K}}(\varphi) + K_\mathrm{p} = \frac{\partial}{\partial \varphi} \left (  A^{-1}(h^{-1}(\varphi)) \,  K(h^{-1}(\varphi)) \right ) + K_\mathrm{p} \succ 0.
\end{equation}
This can be shown via the Lyapunov function~\citep{khalil2002nonlinear, della2020model, della2023model}
\begin{equation}
\begin{split}
    V(\varphi, \dot{\varphi}) =& \: \underbrace{\frac{1}{2} \, \dot{\varphi}^\top \, M_\varphi(h^{-1}(\varphi)) \, \dot{\varphi}}_\text{Kinetic Energy} + \underbrace{\mathcal{U}_{\varphi,\mathrm{K}}(\varphi) - \mathcal{U}_{\varphi,\mathrm{K}}(\varphi^\mathrm{d})}_\text{Centered Elastic Potential Energy}\\
    & \: + \underbrace{K^\top(h^{-1}(\varphi^\mathrm{d})) \, A^{-\top}(h^{-1}(\varphi^\top)) \left ( \varphi^\mathrm{d} - \varphi \right )}_\text{Correction Term} + \underbrace{\frac{1}{2} \, (\varphi^\mathrm{d} - \varphi)^\top \, K_\mathrm{p} \, (\varphi^\mathrm{d} - \varphi)}_\text{Artificial Potential Energy of Feedback},
\end{split}
\end{equation}
with the associated time derivative~\citep{della2023model}
\begin{equation}
    \dot{V}(\varphi,\dot{\varphi}) = -\dot{\varphi}^\top \, \left ( D_\varphi(h^{-1}(\varphi)) + K_\mathrm{d} \right ) \, \dot{\varphi} \leq 0 \quad \forall \: \varphi,\dot{\varphi} \in \mathbb{R}^n
\end{equation}
If the condition from Eq.\ref{eq:background:model_based_control:fully_actuated:regulation_gravity_cancellation:closed_loop_potential_convexity} is locally met for $\varphi = \varphi^\mathrm{d}$, then the setpoint $\varphi^\mathrm{d}$ is locally asymptotically stable. If the convexity condition is met $\forall \: \varphi \in \mathbb{R}^n$, then the setpoint is globally asymptotically stable.
% which are locally asymptotically stable with a sufficiently large proportional feedback gain $K_\mathrm{p} > 0$~\citep{pustina2025analysis}.


Here, it is easy to see how the proportional feedback gain makes the robot stiffer and, with that, can potentially allow for the system to be stable even when the open-loop elastic potential is non-convex. Still, this comes at the cost of decreased compliance and decreased robustness against measurement noise.
In the case of the actuation space elastic potential being convex, i.e., $\frac{\partial}{\partial \varphi} \left (A^{-1}(h^{-1}(\varphi)) \,  K(h^{-1}(\varphi)) \right ) \succ 0$, then the proportional feedback gains are not necessary and can also be chosen as zero.
An interesting case is also when (i) a constant actuation matrix $A(q) = A$, which is, for example, the case for many pneumatically-actuated soft robots, together with (ii) and a convex configuration space elastic potential, as for example the case for linear elasticity $K(q) = S \, q$, where $S\succ 0$. Then, the closed-loop dynamics are given by
\begin{equation}
    M_\varphi(q) \, \ddot{\varphi} +  \eta_\varphi(q,\dot{q}) \, \dot{\varphi} + S_\varphi ( \varphi - \varphi^\mathrm{d} ) + D_\varphi \, \dot{\varphi} = \tau_\mathrm{fb}(t, q, \dot{q}),
\end{equation}
which renders $\varphi^\mathrm{d}$ to be globally asymptotically stable.

% This controller is particularly interesting in the case of (i) a constant actuation matrix $A(q) = A$, which is, for example, the case for many pneumatically-actuated soft robots, together with (ii) and a convex elastic potential, as for example the case for $K(q) = S \, q$, where $S\succ 0$, as then the closed-loop dynamics
% \begin{equation}
%     M_\varphi(q) \, \ddot{\varphi} + \eta_\varphi(q,\dot{q}) \, \dot{\varphi} + A^{-1} \left ( K(q) - K(q^\mathrm{d}) \right ) + D_\varphi \, \dot{\varphi} = \tau_\mathrm{fb}(t, q, \dot{q}),
% \end{equation}
% exhibit a globally asymptotically stable equilibrium at the setpoint $q^\mathrm{d}$, even when the soft robot is not elastically dominated.

\subsubsection{Setpoint Regulation with Cancellation of Static Forces}
Akin to PD+~\citep{kelly1996class, kelly1998global} controllers originally developed for rigid manipulators, we can fully cancel the static, including gravitational and elastic, forces of the soft robot dynamics via nonlinear feedback and achieve setpoint regulation solely based on the potential field established by the (proportional) feedback term. The associated control law is given by~\citep{patterson2024design, pustina2025analysis}
\begin{equation}
    \tau_\mathrm{mb}(q) =  \underbrace{A^{-1}(q) \, G(q)}_\text{Cancel Gravity} + \underbrace{A^{-1}(q^\mathrm{d}) \, K(q^\mathrm{d})}_\text{Cancel Elasticity} \big )
\end{equation}
which results in the closed-loop dynamics
\begin{equation}
    M_\varphi(q) \, \ddot{\varphi} + \eta_\varphi(q,\dot{q}) \, \dot{\varphi} + D_\varphi(q) \, \dot{\varphi} = \tau_\mathrm{fb}(t, q, \dot{q}),
\end{equation}
where the potential of the system is now fully dominated by the feedback controller.
Such a closed-loop system with a proportional feedback term, for example,
\begin{equation}
    M_\varphi(q) \, \ddot{\varphi} + \eta_\varphi(q,\dot{q}) \, \dot{\varphi} +  K_\mathrm{p} ( \varphi - \varphi^\mathrm{d}) + D_\varphi(q) \, \dot{\varphi} = 0_n,
\end{equation}
is for any positive proportional gain $K_\mathrm{p} \succ 0 \in \mathbb{R}^{n \times n}$ globally asymptotically stable - even for small gains.
This can be proven using the Lyapunov function
\begin{equation}
    V(\varphi,\dot{\varphi}) = \frac{1}{2} \, \dot{\varphi}^\top \, M_\varphi(h^{-1}(\varphi)) \, \dot{\varphi} + \frac{1}{2} \, \left (\varphi - \varphi^\mathrm{d} \right )^\top \, K_\mathrm{p} \, \left (\varphi - \varphi^\mathrm{d} \right ),
\end{equation}
that exhibits an associated time derivative of
\begin{equation}
    \dot{V}(\varphi,\dot{\varphi}) = - \dot{\varphi}^\top \, D_\varphi(h^{-1}(\varphi))) \, \dot{\varphi} \leq 0 \quad \forall \varphi, \dot{\varphi} \in \mathbb{R}^n,
\end{equation}
as $D_\varphi \succ 0$. Via LaSalle's invariance principle, \gls{GAS} with respect to the equilibrium $\varphi^\mathrm{d}$ can be shown~\citep{khalil2002nonlinear}.
This strength of global convergence guarantees even for configuration-dependent actuation matrices $A(q)$ comes potentially at the cost of robustness as, particularly for low feedback gains $K_\mathrm{p}$, unmodelled system dynamics could become dominant, causing steady-state errors or even instability.

\subsubsection{Trajectory Tracking with Feedforward Compensation}
In the following, we will assume the actuation matrix to be constant with $A(q) = A$. Then, we can design a trajectory tracking algorithm with feedforward compensation as~\citep{kelly1994pd, della2023model}
\begin{equation}
    \tau_\mathrm{mb}(t) =  \underbrace{M_\varphi(q^\mathrm{d}(t)) \, \ddot{\varphi}^\mathrm{d}(t) + \eta_\varphi(q^\mathrm{d}(t),\dot{q}^\mathrm{d}(t)) \, \dot{\varphi}^\mathrm{d}(t) + D_\varphi \, \dot{q}^\mathrm{d}(t)}_\text{Compensate Dynamic Forces} + \underbrace{ A^{-1} \big ( G(q^\mathrm{d}(t)) + K(q^\mathrm{d}(t)) \big )}_\text{Compensate Static Forces}.
\end{equation}
% This model-based feedforward term generates the closed-loop dynamics
% \begin{equation}
%     M_\varphi(q) \, \ddot{\varphi} + \eta_\varphi(q,\dot{q}) \, \dot{q} + \partial_{\varphi} \mathcal{U}_\varphi(\varphi) - \partial_{\varphi} \mathcal{U}_\varphi(\varphi^\mathrm{d}) + D_\varphi(q) \, \dot{q} = \tau_\mathrm{fb}(t, q, \dot{q}),
% \end{equation}
% After defining $e(t) = q^\mathrm{d}(t) - q(t)$, $e(t) = q^\mathrm{d}(t) - q(t)$
% to be locally asymptotically stable \textcolor{orange}{for a sufficiently large proportional feedback gain $K_\mathrm{p} > 0$}.
This controller is locally asymptotically stable, assuming sufficiently large proportional and dissipative feedback gains~\citep{della2023model}.

\subsubsection{Trajectory Tracking with Mixed State Feedback}
In the following, we will assume the actuation matrix to be constant with $A(q) = A$.
Additionally, as this controller is particularly interesting for soft robots with convex elastic potential, we assume linear elasticity $K(q) = S \, q$ with $S \succ 0$, although the controller would also converge globally work for any convex potential field or locally for non-convex elastic potentials assuming sufficiently large feedback gains. We refer the interested reader to the section on \emph{Setpoint Regulation with Gravity Cancellation and Compensation of Elastic Forces} for an extended discussion on this topic.

A trajectory tracking controller that exhibits full state feedback apart from compensating instead of canceling elastic forces is given by~\citep{kelly1996class, della2020model}
\begin{equation}
    \tau_\mathrm{mb}(t,q,\dot{q}) = \underbrace{M_\varphi(q(t)) \, \ddot{\varphi}^\mathrm{d}(t) + \eta_\varphi(q(t),\dot{q}(t)) \, \dot{\varphi}^\mathrm{d}(t) + A^{-1} \, G(q(t))}_\text{Rigid Manipulator Nonlinear PD/PD+} + \underbrace{S_\varphi \, \varphi^\mathrm{d}(t) + D_\varphi \, \dot{\varphi}^\mathrm{d}(t)}_\text{Shaping Soft Robot Impedance},
\end{equation}
where $S_\varphi = A^{-1} \, S \, A^{-\top} \succ 0 \in \mathbb{R}^{n \times n}$.
This leads to the closed-loop dynamics
\begin{equation}\footnotesize
    M_\varphi(q(t)) \, \left ( \ddot{\varphi}(t) - \ddot{\varphi}^\mathrm{d}(t) \right ) + \eta_\varphi(q(t),\dot{q}(t)) \left ( \dot{\varphi}(t) - \dot{\varphi}^\mathrm{d}(t) \right ) + S_\varphi \left ( \varphi(t) - \varphi^\mathrm{d}(t) \right ) + D_\varphi \left ( \dot{\varphi}(t) - \dot{\varphi}^\mathrm{d}(t) \right ) = \tau_\mathrm{fb}(t,q,\dot{q}).
\end{equation}
% which we can rewrite as
% \begin{equation}\small
%     M_\varphi(q(t)) \, \left ( \ddot{\varphi}(t) - \ddot{\varphi}^\mathrm{d}(t) \right ) + \left ( \eta_\varphi(q(t),\dot{q}(t)) + D_\varphi \right ) \, \left ( \dot{\varphi}(t) - \dot{\varphi}^\mathrm{d}(t) \right ) + A^{-1} \left ( K(A^{-\top} \varphi(t)) - K(A^{-\top} \varphi^\mathrm{d}(t)) \right ) = \tau_\mathrm{fb}(t,q,\dot{q}).
% \end{equation}
The goal is now to show that the closed-loop error dynamics, which are defined as
\begin{equation}
    M_\varphi(q(t)) \, \ddot{e}(t) + \left ( \eta_\varphi(q(t),\dot{q}(t)) + D_\varphi \right ) \, \dot{e}(t) + S_\varphi \, e(t) = \tau_\mathrm{fb}(t,q,\dot{q}),
\end{equation}
with $e(t) = \varphi(t) - \varphi^\mathrm{d}(t) \in \mathbb{R}^n$, $\dot{e}(t) = \dot{\varphi} - \dot{\varphi}^\mathrm{d}(t)$, and $\ddot{e}(t) = \ddot{\varphi}(t) - \ddot{\varphi}^\mathrm{d}(t)$ asymptotically converge to zero: $\lim_{t \to \infty} e(t) = 0$.
Even without pure feedback term (i.e., $\tau_\mathrm{fb}(t,q,\dot{q}) = 0$), the asymptotic convergence to the trajectory $(\varphi^\mathrm{d}, \dot{\varphi}^\mathrm{d}, \ddot{\varphi}^\mathrm{d})$ can be shown via the Lyapunov function
\begin{equation}
    V(e, \dot{e}) = \frac{1}{2} \, \dot{e}^\top \, M_\varphi(h^{-1}(\varphi^\mathrm{d}+e) \, \dot{e}(t) + \frac{1}{2} \, e^\top(t) \, \left ( S_\varphi + K_\mathrm{d} \right ) \, e(t),
\end{equation}
that has the time derivative
\begin{equation}
    \dot{V}(t,e,\dot{e}) = -\dot{e}^\top \left (D_\varphi + K_\mathrm{d} \right ) \, \dot{e} \leq 0 \quad \forall \: e,\dot{e} \in \mathbb{R}^n,
\end{equation}
by applying Barbalat's Lemma~\citep{slotine1991applied, della2020model}.
Here, $K_\mathrm{p}, K_\mathrm{d} \in \mathbb{R}^{n \times n} \succeq 0$ are any PD feedback gains that are optionally applied.
% This is locally the case for sufficiently large proportional and dissipative feedback gains $K_\mathrm{p} > 0$. Alternatively, if (a) the elastic potential is convex, which is typically the case for most soft robots, and (b) the damping matrix is in actuation coordinates . Specifically, the elastic potential needs to meet the condition $\frac{\partial^2 \mathcal{U}_\varphi (\varphi)}{\partial \varphi^2} = \frac{\partial K(A^\top \varphi)}{\partial \varphi} \succ 0$. For linear elastic systems with $K(\varphi) = S \, A^{-\top} \varphi$, this is the case when $S \, A^{-\top} \succ 0$.


\subsection{Model-Based Terms: The Underactuated Case}\label{sub:background:model_based_control:model_based_terms_underactuated}
\textcolor{red}{\begin{itemize}
    \item Feedforward regulator: Refer to \citep{pustina2025analysis}
    \item PD+ regulator: Refer to \citep{pustina2025analysis}
    \item Elastically decoupled soft robots: Refer to \citep{pustina2025analysis}
    \item Elastically dominated soft robots
\end{itemize}}


% \subsubsection{Setpoint Regulation with Compensation of Static Forces}
% The following regulator locally stabilizes the system around the setpoint $\varphi^\mathrm{d} = h(q^\mathrm{d})$ by shaping the potential energy of the first $m$ actuation coordinates~\citep{borja2022energy, della2023model}
% \begin{equation}\label{eq:background:model_based_control:potential_shaping_regulation}
%     \tau_\mathrm{mb}(t, q, \dot{q}) = J_{\mathrm{h},\mathrm{M},\mathrm{a}}^{+\top}(q^\mathrm{d}) \left ( G(q^\mathrm{d}) + K(q^\mathrm{d}) \right ).
% \end{equation}
% This model-based feedforward term renders the closed-loop dynamics
% \begin{equation}
%     M_\varphi(q) \, \ddot{\varphi} + \eta_\varphi(q,\dot{q}) \, \dot{q} + \begin{bmatrix}
%         \partial_{\varphi_\mathrm{a}} \mathcal{U}_\varphi(\varphi) - \partial_{\varphi_\mathrm{a}} \mathcal{U}_\varphi(\varphi^\mathrm{d})\\
%         \partial_{\varphi_\mathrm{u}} \mathcal{U}_\varphi(\varphi)
%     \end{bmatrix} + D_\varphi(q) \, \dot{q} = \begin{bmatrix}
%         \tau_\mathrm{fb}(t, q, \dot{q})\\ 0_{n-m}
%     \end{bmatrix},
% \end{equation}
% to be locally asymptotically stable.

% As mentioned already before, for this regulator to work, $\varphi^\mathrm{d}$ needs to be an attainable equilibrium of the system - especially as we cannot control the behavior of the unactuated coordinates $\varphi_\mathrm{u}$. 

% If the potential field is convex (i.e., $\frac{\partial^2}{\partial \varphi^2}  \mathcal{U}_\varphi(\varphi) \succ 0 \: \forall \varphi \in \mathbb{R}$) this controller is globally asymptotically stable - even with a deactivated feedback term $\tau_\mathrm{fb}(t,q,\dot{q})=0$. If this is not the case, the region of attraction can be increased, or the controller can even be made globally asymptotically stable by sufficiently increasing the proportional gains $K_\mathrm{p}$ of the feedback controller, which makes the robot stiffer.

% \subsubsection{Setpoint Regulation with Gravity Cancellation and Compensation of Elastic Forces}
% As stated previously, Eq.~\ref{eq:background:model_based_control:potential_shaping_regulation}, depending on the gravitational field and for low feedback gains, is only locally asymptotically stable 
% \begin{equation}
%     % \tau_\mathrm{mb}(t, q, \dot{q}) =  J_{\mathrm{h},\mathrm{M},\mathrm{a}}^{+\top}(q) \left ( G(q) + K(q) \right ),
%     \tau_\mathrm{mb}(t, q, \dot{q}) = J_{\mathrm{h},\mathrm{M},\mathrm{a}}^{+\top}(q) \left ( \underbrace{G(q)}_\text{Cancel Gravity} + \underbrace{K(q^\mathrm{d})}_\text{Comp. Elasticity} \right )
% \end{equation}
% leading to the closed-loop dynamics
% \begin{equation}
%     M_\varphi(q) \, \ddot{\varphi} + \eta_\varphi(q,\dot{q}) \, \dot{q} + \begin{bmatrix}
%         J_{\mathrm{h},\mathrm{M},\mathrm{a}}^{+\top}(q) \left ( K(q) - K(q^\mathrm{d}) \right )\\
%         J_{\mathrm{h},\mathrm{M},\mathrm{u}}^{+\top}(q) \left ( K(q) + G(q)) \right )\\
%     \end{bmatrix} + D_\varphi(q) \, \dot{q} = \begin{bmatrix}
%         \tau_\mathrm{fb}(t, q, \dot{q})\\ 0_{n-m}
%     \end{bmatrix}.
% \end{equation}
% \citet{pustina2022feedback} has 

% \subsubsection{Trajectory Tracking with Compensation of Static Forces}
% \begin{equation}
%     \tau_\mathrm{mb}(t, q, \dot{q}) = M_{\varphi,\mathrm{a}}(q^\mathrm{d}) \, \ddot{\varphi}^\mathrm{d} + \eta_{\varphi,\mathrm{a}}(q^\mathrm{d},\dot{q}^\mathrm{d}) \, \dot{q}^\mathrm{d} + J_{\mathrm{h},\mathrm{M},\mathrm{a}}^{+\top}(q^\mathrm{d}) \left ( G(q^\mathrm{d}) + K(q^\mathrm{d}) + D \, \dot{q}^\mathrm{d} \right )
% \end{equation}


% \subsubsection{Trajectory Tracking with Cancellation of Static Forces}
% \begin{equation}
%     \tau_\mathrm{mb}(t, q, \dot{q}) = M_{\varphi,\mathrm{a}}(q) \, \ddot{\varphi}^\mathrm{d} + \eta_{\varphi,\mathrm{a}}(q,\dot{q}) \, \dot{q}^\mathrm{d} + J_{\mathrm{h},\mathrm{M},\mathrm{a}}^{+\top}(q) \left ( G(q) + K(q) \right ),
% \end{equation}
% leading to the closed-loop dynamics
% \begin{equation}
%     M_\varphi(q) \, \ddot{\varphi} + \begin{bmatrix}
        
%     \end{bmatrix} \eta_\varphi(q,\dot{q}) \, \dot{q} + \begin{bmatrix}
%         0_m\\ J_{\mathrm{h},\mathrm{M},\mathrm{u}}^{+\top}(q) \left ( G(q) + K(q) + D \, \dot{q} \right )
%     \end{bmatrix} = \begin{bmatrix}
%         \tau_\mathrm{fb}(t, q, \dot{q})\\ 0_{n-m}
%     \end{bmatrix}.
% \end{equation}

\subsection{Integrated Controllers}\label{sub:background:model_based_control:integrated_controllers}
In the following, we will discuss some common closed-form model-based controllers that cannot (easily) be separated into a model-based term and a pure feedback term.
For simplicity, we assume in the following the fully actuated case - i.e., $n=m$, $\varphi = \varphi_\mathrm{a}$, $M_{\varphi}(q) = M_{\varphi,\mathrm{a}}(q)$, etc.

\subsubsection{P-satI-D+Potential Shaping}
The \emph{P-satI-D+Potential Shaping} controller consists of \emph{P-satI-D} feedback term and the \emph{Setpoint Regulation with Feedforward Compensation} model-based term.
As we frequently use this controller throughout this thesis, such as in Chapter~\ref{chp:hsacontrol} (underactuated version), and Chapter~\ref{chp:pcsregression} \& \ref{chp:con}, we will below specify the control law
\begin{equation}
\begin{split}
    \tau(t,q,\dot{q}) =& \: \underbrace{A^{-1} \, \left ( G(q^\mathrm{d}) + K(q^\mathrm{d}) \right )}_\text{Model-Based Feedforward}\\
    & \: + \underbrace{K_\mathrm{p} \left (\varphi^\mathrm{d}(t) - \varphi(t) \right ) + K_\mathrm{d} \left ( \dot{\varphi}^\mathrm{d}(t) - \dot{\varphi}(t) \right ) + K_\mathrm{i} \int_0^t \tanh \left ( \gamma \, ( \varphi^\mathrm{d}(t')-\varphi(t') ) \right ) \: \mathrm{d} t'}_\text{Model-Free Feedback Term: P-satI-D},
\end{split}
\end{equation}
which generates the closed-loop dynamics
\begin{equation}
\begin{split}
    M_\varphi(q) \, \ddot{\varphi} + \eta_\varphi(q,\dot{q}) \, \dot{\varphi} + A^{-1} \left ( G(q) + K(q) - G(q^\mathrm{d}) - K(q^\mathrm{d}) \right ) + D_\varphi \, \dot{\varphi}\\
    + K_\mathrm{p} \left (\varphi(t) - \varphi^\mathrm{d}(t) \right ) + K_\mathrm{d} \left ( \dot{\varphi}(t) - \dot{\varphi}^\mathrm{d}(t) \right ) + K_\mathrm{i} \int_0^t \tanh \left ( \gamma \, ( \varphi(t')-\varphi^\mathrm{d}(t') ) \right ) \: \mathrm{d} t' = 0_n,
\end{split}
\end{equation}
where we assume a constant actuation matrix $A(q) = A$.

% In case of linear elasticity $K(q) = S \, q$, the closed loop dynamics simplify to 

\subsubsection{Feedback Linearization via Computed Torque}
The idea behind (full) feedback linearization~\citep{slotine1987on, spong2020robot} is to 
cancel the existing dynamics of the robot and ensure that the closed-loop system exhibits linear dynamics - usually established via a PD term. A computed torque controller for soft robots exhibits the form
\begin{equation}\small
    \tau(t,q,\dot{q}) = M_{\varphi}(q) \, \left (K_\mathrm{p} \left (\varphi^\mathrm{d} - \varphi \right ) + K_\mathrm{d} \left (\dot{\varphi}^\mathrm{d} - \dot{\varphi} \right ) + \ddot{\varphi}^\mathrm{d}\right ) + \left ( \eta_{\varphi}(q,\dot{q}) + D_\varphi(q) \right ) \, \dot{\varphi} + A^{-1}(q) \left ( G(q) + K(q) \right ),
\end{equation}
where $K_\mathrm{p}, K_\mathrm{d} \in \mathbb{R}^{m \times m}$ are proportional and derivative control gains for tracking the desired actuation coordinate and actuation velocity, respectively. 
The closed-loop dynamics read as
\begin{equation}\label{eq:background:model_based_control:feedback_linearization:closed_loop_dynamics}
    M_{\varphi}(q) \left (K_\mathrm{p} \left (\varphi - \varphi^\mathrm{d} \right ) + K_\mathrm{d} \left (\dot{\varphi} - \dot{\varphi}^\mathrm{d} \right ) + \left ( \ddot{\varphi} - \ddot{\varphi}^\mathrm{d} \right ) \right ) = 0.
\end{equation}
After defining the control error as $e(t) = \varphi(t) - \varphi^\mathrm{d}(t)$ with $\dot{e}(t) = \dot{\varphi}(t) - \dot{\varphi}^\mathrm{d}(t)$ and $\ddot{e}(t) = \ddot{\varphi}(t) - \ddot{\varphi}^\mathrm{d}(t)$, the dynamics of Eq.~\ref{eq:background:model_based_control:feedback_linearization:closed_loop_dynamics} can be rewritten as
\begin{equation}
    \ddot{e}(t) + K_\mathrm{d} \, \dot{e}(t) + K_\mathrm{p} \, e(t) = 0,
\end{equation}
which lets us notice that now linear dynamics govern with stiffness $K_\mathrm{p}$ and damping factor $K_\mathrm{d}$ govern the closed-loop system behavior.
If we assume scalar control gains $K_\mathrm{p}, K_\mathrm{d} \in \mathbb{R}_+$, these error dynamics converge exponentially fast to the global equilibrium $e(t) = 0$ with decay time $\frac{1}{K_\mathrm{d}}$. Specifically, we can always choose the control such that the closed-loop system exhibits a critically damped behavior $\frac{K_\mathrm{d}}{2} = \sqrt{K_\mathrm{p}}$
\begin{equation}\label{eq:background:model_based_control:feedback_linearization:error_evolution_closed_form}
    e(t) = \left ( e_0 + \left ( \dot{e}_0 + \frac{K_\mathrm{d}}{2} \, e_0 \right ) (t-t_0) \right ) \, e^{-\frac{K_\mathrm{d}}{2} (t - t_0)},
\end{equation}
where $e_0, \dot{e}_0$ are the initial error and its velocity at $t_0$.

As seen in this derivation, computed torque controllers exhibit very nice stability and convergence properties. However, this comes at the cost of requiring high control rates, precise actuator motion, high control effort, and, most importantly, very accurate modeling of the system dynamics. In case of modeling errors, the stability characteristics can be lost, and the unmodelled dynamics can quickly become dominant.
So far, computed torque controllers have been verified for fully actuated soft robots in simulation~\citep{boyer2006macro, pustina2024unified}, but to the best of our knowledge, not yet experimentally.


\subsubsection{Operational Space Impedance Control}
% A operational space impedance controller leverages the partial feedback linearization framework to cancel out the existing task dynamics and establish new linear dynamics with stiffness matrix $K_\mathrm{x} \in \mathbb{R}^{o \times o}$ and damping matrix $D_\mathrm{x} \in \mathbb{R}^{o \times o}$ that regulates the closed-loop system towards the operational space reference $x^\mathrm{d} \in \mathbb{R}^o$~\citep{khatib1987unified, della2020model}
A operational space impedance controller uses partial feedback linearization to cancel out the original task dynamics and replace them with a new set of linear dynamics in operational space. These new dynamics are defined by a stiffness matrix $K_\mathrm{x} \in \mathbb{R}^{o \times o}$ and a damping matrix $D_\mathrm{x} \in \mathbb{R}^{o \times o}$, which together drive the closed-loop system toward the desired operational space reference $x^\mathrm{d} \in \mathbb{R}^o$~\citep{khatib1987unified, della2020model}.
\begin{equation}\small
\begin{split}
    \tau =& \: \underbrace{A^{-1}(q)}_{J_\mathrm{h}^{-\top}(q)} \, \big ( \underbrace{J^\top(q) \, J_\mathrm{M}^{+\top}(q) \left ( K(q) + D \, \dot{q} \right )}_\text{Cancel Elastic \& Diss. Forc. Acting on Task} + \underbrace{G(q)}_\text{Cancel Gravity} \big )\\
    + & \: A^{-1}(q) \, \big ( \underbrace{J^\top(q) \, \eta_\mathrm{x}(q,\dot{q}) \left ( \mathbb{I}_n - J_\mathrm{M}^{+}(q) \, J(q)  \right ) \, \dot{q}}_\text{Cancel Coupling of Null-Space Coriolis Force on Task} + \underbrace{J^\top(q) \left ( K_\mathrm{x} \, (x^\mathrm{d} - x) - D_\mathrm{x} \, \dot{x} \right )}_{\text{PD for Shaping Operational Space Impedance}} \big ),
\end{split}
\end{equation}
% As previously already mentioned, this impedance controller assumes (a) full actuation (i.e., $n=m$), (b) that $A(q) \in \mathbb{R}{n \times n}$ is invertible~\citep{della2020model}, (c) the dimensionality of the operational space with coordinates $x \in \mathrm{R}^\mathrm{o}$ is smaller than the of the configuration space (i.e., $m \leq n$), and (d) that the null-space is asymptotically stable which should generally be the case if $K(q) = S \, q$ with $S \succ 0$ and $D \succ 0$.
As noted earlier, the impedance controller relies on several key assumptions. It presumes (a) full actuation (i.e., $n = m$), (b) that the matrix $A(q) \in \mathbb{R}^{n \times n}$ is invertible~\citep{della2020model}, (c) that the operational space—characterized by coordinates $x \in \mathbb{R}^{o}$—has lower dimensionality than the configuration space (i.e., $m \leq n$), and (d) that the null space is asymptotically stable, a condition typically met when $K(q) = S \, q$ with $S \succ 0$ and $D \succ 0$.

In the following, we will guide you step-by-step through the control design.
First, we cancel the gravitational forces of the system via $\tau_\mathrm{q} = G(q)$. Please note that this immediately ensures that gravity is not acting anymore on the closed-loop null-space dynamics, which could potentially cause instability.
Now, the updated task and null space dynamics are given by
\begin{equation}
    \begin{bmatrix}
        \Lambda_\mathrm{x}(q) & 0_{o \times (n-o)}\\
        0_{(n-o) \times o} & \Lambda_\mathrm{n}(q)
    \end{bmatrix} \, \begin{bmatrix}
        \ddot{x}\\
        \dot{\nu}_\mathrm{n}
    \end{bmatrix} + \begin{bmatrix}
        \eta_\mathrm{xx}(q,\dot{q}) & \eta_\mathrm{xn}(q,\dot{q})\\
        \eta_\mathrm{nx}(q,\dot{q}) & \eta_\mathrm{nn}(q,\dot{q})
    \end{bmatrix} \, \begin{bmatrix}
        \dot{x}\\ \nu_\mathrm{n}
    \end{bmatrix} + \begin{bmatrix}
        J_\mathrm{B}^{+\top}(q)\\
        Z(q)
    \end{bmatrix} \, \left ( K(q) + D \, \dot{q} \right ) = \begin{bmatrix}
        f_\mathrm{x}\\ f_\mathrm{n}
    \end{bmatrix},
\end{equation}
Next, we devise a force $f_\mathrm{x} \in \mathbb{R}^o$ in operational space
\begin{equation}
    f_\mathrm{x} = \underbrace{J_\mathrm{M}^{+\top}(q) \left ( K(q) + D \, \dot{q} \right )}_{f_\mathrm{KD}}
    + \underbrace{\eta_\mathrm{x}(q,\dot{q}) \left ( \mathbb{I}_n - J_\mathrm{M}^{+}(q) \, J(q)  \right ) \, \dot{q}}_{f_{\eta_\mathrm{xn}}}
    + \underbrace{K_\mathrm{x} \, (x^\mathrm{d} - x) - D_\mathrm{x} \, \dot{x}}_{f_\mathrm{PD}}
\end{equation}
that cancels the existing operational space dynamics, removes the remaining coupling from the null space dynamics, and creates new linear dynamics with a tunable impedance and an asymptotically stable equilibrium at $x^\mathrm{d}$ via a PD term. 
Diving into more detail, the force $f_\mathrm{KD}$ cancels the existing operational space elastic and dissipative forces.
Next, the purpose of the term $f_{\eta_\mathrm{xn}}$ is to remove the remaining coupling of the null space dynamics on the operational space dynamics from the closed loop system. Specifically, the aim is to eliminate the Coriolis forces of the null space acting on the operational space $\eta_\mathrm{xn}(q,\dot{q}) \, \nu_\mathrm{n}$. However, we want to avoid having to compute the null space online. We can avoid the derivation of the null space by performing the substitution~\citep{ott2008cartesian, della2020model}
\begin{equation}
\begin{split}
    f_{\eta_\mathrm{xn}} =& \: \eta_\mathrm{xn}(q,\dot{q}) \, \nu_\mathrm{n} = \eta_\mathrm{x}(q,\dot{q}) \, \dot{q} - \eta_\mathrm{xx}(q,\dot{q}) \, \dot{q},\\
    =& \: \eta_\mathrm{x}(q,\dot{q}) \, \dot{q} - \eta_\mathrm{x}(q,\dot{q}) \, J_\mathrm{M}^+(q) \, \dot{x} = \eta_\mathrm{x}(q,\dot{q}) \, \dot{q} - \eta_\mathrm{x}(q,\dot{q}) \, J_\mathrm{M}^+(q) \, J(q) \, \dot{q}\\
    =& \: \eta_\mathrm{x}(q,\dot{q}) \left ( \mathbb{I}_n - J_\mathrm{M}^{+}(q) \, J(q)  \right ) \, \dot{q},
\end{split}
\end{equation}
as $\dot{x} = J(q) \, \dot{q}$ and $\eta_\mathrm{xx}(q,\dot{q}) = \eta_\mathrm{x}(q,\dot{q}) \, J_\mathrm{M}^+(q)$.
The removal of the existing operational space dynamics allows us then to establish the desired impedance. Specifically, PD term $f_\mathrm{PD}$ creates an artificial potential field $\mathcal{U}_\mathrm{x}(x) = \frac{1}{2}x^\top \, K_\mathrm{x} \, x$ and establishes dissipation which ensures asymptotic stability of the operational space dynamics.
This forcing $f_\mathrm{x}$ results in the closed-loop task and null space dynamics
\begin{equation}
    \begin{bmatrix}
        \Lambda_\mathrm{x}(q) & 0_{o \times (n-o)}\\
        0_{(n-o) \times o} & \Lambda_\mathrm{n}(q)
    \end{bmatrix} \, \begin{bmatrix}
        \ddot{x}\\
        \dot{\nu}_\mathrm{n}
    \end{bmatrix} + \begin{bmatrix}
        \eta_\mathrm{xx}(q,\dot{q}) & 0_{o \times (n-o)}\\
        \eta_\mathrm{nx}(q,\dot{q}) & \eta_\mathrm{nn}(q,\dot{q})
    \end{bmatrix} \, \begin{bmatrix}
        \dot{x}\\ \nu_\mathrm{n}
    \end{bmatrix} + \begin{bmatrix}
        K_\mathrm{x} \, (x - x^\mathrm{d}) - D_\mathrm{x} \, \dot{x}\\
        Z(q) \left ( K(q) + D \, \dot{q} \right )
    \end{bmatrix} = 0_{n},
\end{equation}
We can extract several interesting observations by analyzing these closed-loop dynamics in more detail. First, the operational space dynamics
\begin{equation}
    \Lambda_\mathrm{x}(q) \, \ddot{x} + K_\mathrm{x} \, (x - x^\mathrm{d}) - D_\mathrm{x} \, \dot{x} = 0_{o},
\end{equation}
now mirror the ones of coupled damped harmonic oscillators, and we can easily prove, analog to the computed torque controller, that they converge exponentially fast to the global asymptotic equilibrium $x^\mathrm{d}$.
In the spirit of the previously introduced setpoint regulation controllers with gravity cancellation and compensation of elastic forces, we don't fully eliminate the null space dynamics but instead increase robustness against disturbances and modeling errors by preserving the natural elasticity and dissipation of the system while only removing the gravitational forces. This results in closed-loop null-space dynamics that converge in steady-state to the minimum of the operational space potential field.

After designing the desired forces in operational space $f_\mathrm{x}$, we can easily derive the control input via configuration space. First, $f_\mathrm{x}$ is projected into configuration space, resulting in a sum between the projected operational space forces and the gravity cancellation: $\tau_\mathrm{q} = J^\top(q) \, f + G(q)$ 
Finally, the inverse of the actuation matrix can be used to devise the control input based on the desired configuration space torques $\tau = A^{-1}(q) \, \tau_\mathrm{q}$.

We propose a variation of this operational space impedance controller that is specialized to Cartesian control of underactuated planar \gls{HSA} robots in Chapter~\ref{chp:hsacontrol}.
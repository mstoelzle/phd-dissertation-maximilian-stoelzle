\section{Model-Based Control}\label{sec:background:model_based_control}
% In this section, we review existing model-based controllers for soft robots whose control law is available in closed form.
% Many of these control approaches appear at various points throughout the thesis, such as the P-satI-D+potential shaping controller in Section~\ref{sec:hsacontrol:configuration_space_regulation} and Chapter~\ref{chp:pcsregression} \& \ref{chp:con}, the PD+ controller in a version additionally also considering the actuator dynamics via backstepping in Chapter~\ref{chp:backstepping} and the operational space impedance controller in Section~\ref{sec:hsacontrol:operational_space_impedance_control}.
% This section only contains a top-level discussion of the most common closed-form model-based control laws that have been developed for soft robots. For a more detailed discussion of the controllers, including stability proofs using Lyapunov arguments, we point the interested reader to the respective publications~\citep{della2020model, pustina2022feedback, pustina2022p, borja2022energy, della2023model}. For an in-depth study of the control of underactuated soft robots, we recommend \citet{pustina2025analysis}.
In this section, we review recently proposed closed-form controllers for soft robots that can leverage advanced nonlinear models\footnote{Please note that this excludes approaches relying on linear/linearized models such as \gls{LQR} and that model-based controllers that are not available in closed-form, such as \gls{MPC}, are out of scope of this thesis.}. Many of these approaches appear throughout the thesis, such as the P-satI-D+potential shaping controller in Section~\ref{sec:hsacontrol:configuration_space_regulation} and Chapters~\ref{chp:pcsregression} and \ref{chp:con}, the PD+ controller—augmented with backstepping to consider actuator dynamics—in Chapter~\ref{chp:backstepping}, and the operational space impedance controller in Section~\ref{sec:hsacontrol:operational_space_impedance_control}. This section provides a high-level overview of the most common closed-form model-based control laws developed for soft robots. For a more detailed discussion of these controllers, including Lyapunov-based stability proofs, interested readers should consult the respective publications~\citep{della2020model, pustina2022feedback, pustina2022p, borja2022energy, della2023model}. For an in-depth study of controlling underactuated soft robots, we recommend the thesis by \citet{pustina2025analysis}.

% Differently from most of the existing literature that formulates the controllers in configuration space~\cite{della2020model, della2023model, caasenbrood2021energy}, we formulate most control laws directly in actuation space. The reason for that is that even for fully actuated soft robots (i.e., where the number of configuration variables is equal to the number of actuators), it greatly simplifies the design and convergence analysis of controllers, specifically for configuration-dependent actuation matrices $A(q)$, which are widespread, for example for tendon-driven soft robots.
% The limitation of this strategy is that a mapping into actuation coordinates needs to be found in order to formulate the dynamics in actuation space, which we have shown in Section~\ref{sub:background:dynamics:actuation_space}.
% Furthermore, the experimental verification of actuation-space controllers is currently very limited~\citep{pustina2025analysis, stolzle2024experimental}.
Unlike much of the existing literature, which formulates controllers in configuration space~\citep{della2020model, della2023model, caasenbrood2021energy}, we develop most control laws directly in actuation space. This approach simplifies both the design and convergence analysis of controllers—even for fully actuated soft robots, where the number of configuration variables equals the number of actuators—especially when dealing with configuration-dependent actuation matrices $A(q)$ that are common in tendon-driven soft robots. 
% The limitation of this strategy is that a mapping into actuation coordinates needs to be found in order to formulate the dynamics in actuation space, which we have shown in Section~\ref{sub:background:dynamics:actuation_space}.
% Furthermore, the experimental verification of actuation-space controllers is currently very limited~\citep{pustina2025analysis, stolzle2024experimental}.
The limitation of this strategy is that it requires establishing a mapping into actuation coordinates to formulate the dynamics in actuation space, as shown in Section~\ref{sub:background:dynamics:actuation_space}, which might not always possible. Additionally, experimental validation of actuation-space controllers remains very limited~\citep{pustina2025analysis, stolzle2024experimental}.

\subsection{Preliminaries}
% For simplicity, we refer in the following to the fully actuated case and specifically the case of an identified actuation matrix $A = \mathbb{I}_n$.
% For an extended discussion on the control in the underactuated setting (i.e., $m < n$), we refer the interested reader to \citet{pustina2025analysis}.

\subsubsection{Problem Statement}
% The literature on closed-form model-based controllers mostly considers two problem settings~\citep{sciavicco2012modelling}: \emph{setpoint regulation} and \emph{trajectory tracking}.
% Generally, a reference trajectory is defined with the tuple $(q^\mathrm{d}(t), \dot{q}^\mathrm{d}(t), \ddot{q}^\mathrm{d}(t))$ consisting of the desired configuration, configuration velocity, and configuration acceleration at the current time step.
% Now, we strive to design a \emph{trajectory tracking} controller that allows the soft robotic system to track the reference trajectory as accurately as possible while rejecting any disturbances that might act on the system.
% If we only care about the goal of a motion, we can simplify the problem to a \emph{setpoint regulation} scenario, where a controller regulates the system towards a desired configuration $q^\mathrm{d}$. In the setpoint regulation case, we simply set $\dot{q}^\mathrm{d} = 0$.
% Please note that such motion references, either setpoints or trajectories, can be not just specified in configuration space but given in a variety of coordinate frames. We will discuss this aspect further below in the subsection \emph{Coordinate Frames}.
The literature on closed-form model-based controllers generally considers two problem settings~\citep{sciavicco2012modelling}: \emph{setpoint regulation} and \emph{trajectory tracking}. Typically, a reference trajectory is represented by the tuple $(q^\mathrm{d}(t), \dot{q}^\mathrm{d}(t), \ddot{q}^\mathrm{d}(t))$, which comprises the desired configuration, velocity, and acceleration at each time step. For \emph{trajectory tracking}, our objective is to design a controller that enables the soft robotic system to follow the reference trajectory, and specifically its positional references, as precisely as possible while rejecting any disturbances
\begin{equation}
    \lim_{t \to \infty} \left ( q^\mathrm{d}(t) - q(t) \right ) = 0_n.
\end{equation}
Please note that we typically require both $q^\mathrm{d}(t)$ and $\dot{q}^\mathrm{d}(t)$ to be bounded. Therefore, two positive constants $\gamma_q, \gamma_{\dot{q}} > 0$ need to exist such that~\citep{della2020model}
\begin{equation}
    \lVert q^\mathrm{d}(t) \rVert < \gamma_q,
    \qquad
    \lVert \dot{q}^\mathrm{d}(t) \rVert < \gamma_{\dot{q}}.
\end{equation}
Alternatively, if only the final goal of the motion is of interest, the problem can be simplified to a \emph{setpoint regulation} scenario, where the controller drives the system toward a desired configuration $q^\mathrm{d}$ (with $\dot{q}^\mathrm{d} = 0$).
Then, we would like to design a regulator that achieves the following asymptotic convergence
\begin{equation}
    \lim_{t \to \infty} \left ( q^\mathrm{d} - q(t) \right ) = 0_n.
\end{equation}
Note that these motion references—whether setpoints or trajectories—can be specified not only in configuration space but also in various coordinate frames, a topic we discuss further in the subsection \emph{Coordinate Frames}.

\subsubsection{Control Design Objectives}
% When we devise a model-based controller, we usually pursue several, possibly competing, goals. In the following section, we will detail a selection of these criteria, making it possible to compare the tradeoffs between various model-based controllers.
When designing a model-based controller, we often balance several, sometimes conflicting, objectives. The following section outlines a selection of these criteria, enabling a comparison of the tradeoffs between various model-based controllers.

\begin{itemize}
    \item \textbf{Control Frequency/Computational Complexity.} 
    % In this thesis, we strive for the control law to be available in closed form, which significantly increases the computational efficiency compared to, for example, optimization-based approaches and allows for higher control frequencies, which improves performance and reduces the risk of instability for feedback controllers. When a closed-form control law is available, the computational complexity comes down to (a) the model complexity and (b) which terms of the models need to be evaluated for the controller. For example, a potential shaping controller only requiring access to the potential forces is computationally more efficient than a computed torque controller that requires evaluation of all dynamical matrices within the \glspl{EOM}. 
    In this thesis, we aim to derive a control law in closed form, which greatly enhances computational efficiency compared to, for example, optimization-based methods and supports higher control frequencies. This improvement not only boosts performance but also reduces the risk of instability in feedback controllers. When a closed-form control law is available, the computational complexity is determined by (a) the complexity of the model and (b) the specific model terms that must be evaluated for the controller. For instance, a potential shaping controller, which requires only knowledge about the potential forces, is computationally more efficient than a computed torque controller that necessitates evaluating all the dynamical matrices within the \glspl{EOM}.
    % \item \textbf{Stability.} Generally, we strive for exponential global asymptotic stability of the closed-loop system. This is best illustrated in the setpoint regulation scenarios, where we strive for it to converge to a given setpoint. In the case of \gls{GAS}, no matter with which state the system is initialized, it will always converge to the setpoint with an exponential rate of convergence~\citep{khalil2002nonlinear}. If exponential convergence is not possible, we strive for asymptotic stability, which still guarantees convergence but while losing lower bounds on the rate of convergence rates. In case the controller is not able to achieve \gls{GAS}, we at least strive to guarantee local asymptotic stability around the setpoint. This means that when the system state is initialized within a region of attraction around the setpoint, it will stabilize the system around this local attractive equilibrium of the system, and the system will converge to this setpoint. However, the system might exhibit other stable or unstable equilibria, which means that if the system is initialized outside the region of attraction of the setpoint, it will (likely) not converge.
    \item \textbf{Stability.}  Our goal is generally to achieve exponential \gls{GAS} of the closed-loop system. This is best demonstrated in setpoint regulation scenarios, where the system should converge to a specified setpoint regardless of its initial state and do so at an exponential rate~\citep{khalil2002nonlinear}. If exponential convergence is unattainable, we still aim for asymptotic stability, which ensures convergence but without a guaranteed rate. At a minimum, we require local asymptotic stability around the setpoint, meaning that if the system state starts within a certain region of attraction, it will stabilize at the setpoint. However, if initialized outside this region, the system may not converge due to the presence of other stable or unstable equilibria.
    \item \textbf{Control Effort.} 
    % To enable more energy-efficient (mobile) robots, we strive to reduce the power consumed by the actuator, consisting of the applied force/torque $\tau$ and the associated actuator velocity $\dot{\mu}$. As the required steady-state force is usually fixed by the soft robot design \& the given task, we mainly focus on reducing the control effort\footnote{In optimal control, this can be accomplished by adding a regularization term on the control input $\tau$ to the cost function.} - which is usually defined as the integral of $\tau$ over time, and with that, reduces the needed actuator velocity $\dot{\mu}$ and the consumed power.
    To facilitate energy-efficient (mobile) robots, we strive to minimize the power consumed by the actuators, which includes both the applied force/torque $\tau$ and the corresponding actuator velocity $\dot{\mu}$. Since the necessary steady-state force is typically determined by the soft robot’s design and the task at hand, our focus is on reducing the control effort—often defined as the integral of $\tau$ over time—which in turn reduces the required actuator velocity and overall power consumption.
    \item \textbf{Compliance.} 
    % For augmenting the mechanical compliance of soft robots, we strive for the controller also to exhibit compliant behavior. Specifically, this means that the feedback controller should exhibit as low as possible integral gains as they reduce the stability margins and can cause safety issues, and low proportional feedback gains as they increase the stiffness of the closed-loop system - which makes the soft robot body less soft than desired.
    To complement the inherent mechanical compliance of soft robots, the controller should also be compliant. This means designing feedback controllers with minimal integral gains to avoid compromising stability margins and potential safety issues, as well as using low proportional feedback gains to prevent increasing the closed-loop stiffness—ensuring the robot retains its desired softness. Model-based control approaches actually generally allow us to analyze the closed-loop compliance~\citep{stella2023prescribing} and to certify that they match the task requirements.
    \item \textbf{Robustness.} 
    % Model-based controllers exploit our knowledge about the system behavior to design smart feedback and feedforward terms and modulate the dynamics of the closed-loop system in such a way that they make control easier. However, in reality, as said beautifully by \citet{box1976science}, "All models are wrong." controllers that assume perfect model knowledge to cancel out all or most of the existing system dynamics, as one based on feedback linearization are very sensitive to modeling errors. The reason for that is that when the modeled dynamics are canceled out, the unmodelled dynamics can quickly dominate the shaped dynamics (e.g., the linear dynamics), possibly inducing instability and leading to bad system performance. On the other hand, pure model-based feedforward controllers that do not depend on the current system state are often more robust to modeling errors as they reshape the system dynamics instead of fully \emph{deleting} it and trying to reconstruct it from scratch.
    Model-based controllers leverage our understanding of system behavior to craft intelligent feedback and feedforward components that simplify control. However, as \citet{box1976science} aptly noted, “All models are wrong.” Controllers that rely on perfect model knowledge to cancel out most of the system dynamics, such as those based on feedback linearization, are highly sensitive to modeling errors. When the modeled dynamics are canceled, any unmodeled dynamics can quickly dominate, potentially inducing instability and poor performance. In contrast, model-based feedforward controllers, employing partial cancellations or energy shaping, tend to be more robust to modeling errors, as they reshape rather than entirely eliminate the open-loop system dynamics.
\end{itemize}

\subsubsection{Coordinate Frames}
% In the following, we will introduce several coordinate frames in which control laws can be designed and we lay out the advantages and drawbacks of each strategy.
In the following section, we introduce several coordinate frames for designing control laws and outline the advantages and disadvantages of each approach.

\paragraph{Control in Configuration Space.}
% As introduced in Sec.~\ref{sec:background:kinematics}, the configuration space is usually defined as the kinematic variables parametrizing the backbone shape of the soft robot. Therefore, control in configuration space is also referred to as \emph{shape control}. The advantage of devising a controller in configuration space is that naturally, the robot dynamics are also defined here (see Eq.~\ref{eq:background:dynamics:eom}), which makes the controller law derivation usually simpler and easier to prove stability. Disadvantages include that (a) it can be challenging to come up with a (consistent) reference in configuration space as the actual important motion is usually defined in operational space and, in particular in underactuated settings, not all configurations can actually be (statically) achieved by the actuators~\citep{della2025pushing}, and (b) the mapping of control inputs defined as generalized torques into an actuation $\tau$ can be challenging - specifically when $A(q)$ exhibits singularities or again, when the soft robot is underactuated, which requires special controllers~\citep{pustina2022feedback}.
As introduced in Sec.\ref{sec:background:kinematics}, the configuration space is typically defined by the kinematic variables that parameterize the soft robot’s backbone shape, which is why control in this space is often referred to as \emph{shape control}. One advantage of designing a controller in configuration space is that the robot dynamics are naturally defined here (see Eq.\ref{eq:background:dynamics:eom}), making it simpler to derive the control law and prove its stability. However, there are disadvantages: (a) establishing a consistent reference in configuration space can be challenging since the key motion is often specified in operational space, and in underactuated settings, not all configurations can be statically achieved by the actuators~\citep{della2025pushing}; and (b) mapping control inputs defined as generalized torques into an actuation $\tau$ can be difficult—especially when $A(q)$ exhibits singularities or when the soft robot is underactuated, which requires specialized controllers~\citep{pustina2022feedback}.


\paragraph{Control in Actuation Space.}
% To overcome the previously mentioned difficulties of mapping generalized torques into actuator signals, we can leverage the collocated dynamics~\citep{pustina2024input} presented in Sec.~\ref{sub:background:dynamics:actuation_space} to devise controllers directly in actuation space. Even in the underactuated setting, the first $m$ actuation coordinates $\varphi_\mathrm{a}$ are all directly forced by $\tau$ through an identity actuation matrix, making the derivation of controllers much easier.
% In practice, a configuration-space reference $(q^\mathrm{d},\dot{q}^\mathrm{d})$ can be transformed into an actuation-space referenced through 
To address the challenges of mapping generalized torques into actuator signals, we can exploit the collocated dynamics~\citep{pustina2024input} presented in Sec.~\ref{sub:background:dynamics:actuation_space} to design controllers directly in actuation space. Even in underactuated scenarios, the first $m$ actuation coordinates $\varphi_\mathrm{a}$ are directly influenced by $\tau$ through an identity actuation matrix, significantly simplifying the derivation of controllers. In practice, a configuration-space reference $(q^\mathrm{d},\dot{q}^\mathrm{d})$ can be transformed into an actuation-space reference using
\begin{equation}
    \varphi^\mathrm{d} = h(q^\mathrm{d}),
    \qquad
    \dot{\varphi}^\mathrm{d} = J_\mathrm{h}(q^\mathrm{d}) \, \dot{q},
    \qquad
    \ddot{\varphi}^\mathrm{d} = J_\mathrm{h}(q^\mathrm{d}) \, \ddot{q}^\mathrm{d} + \dot{J}_\mathrm{h}(q^\mathrm{d}) \, \dot{q}^\mathrm{d}.
\end{equation}
% In addition to the simple mapping of control inputs into an actuation $\tau$, we can also easily enforce actuator limits.
% Similar to the case of control in configuration space, a challenge can be to devise a consistent actuation-space reference.
This approach not only simplifies the mapping of control inputs into an actuation $\tau$ but also makes it easier to enforce actuator limits. Nevertheless, devising a consistent actuation-space reference, specifically one that is statically or dynamically feasible, remains a challenge.

\paragraph{Control in Operational Space.}
% Here, the dynamics defined in Eq.~\ref{eq:background:dynamics:eom_task_space} are leveraged to directly devise a controller in operational space~\citep{khatib1987unified}, where the dimensionality $o$ of the operational space reference (generally) needs to fulfill the condition $o \leq n$.
% Specifically, operational space impedance controllers are popular as they allow the specification of operational space stiffness, which is directly relevant to robot-environment interactions. Furthermore, as the reference is usually directly given in operational space, no complex inverse kinematics routine is necessary.
% Disadvantages include the lack of formal stability guarantees, specifically with respect to the null-space dynamics, and the integration of actuator limits being much more challenging.
In this setting, we use the dynamics defined in Eq.\ref{eq:background:dynamics:eom_task_space} to directly design a controller in operational space~\citep{khatib1987unified}. Typically, the operational space reference’s dimensionality $o$ must satisfy $o \leq n$. Operational space impedance controllers are particularly popular because they allow for direct specification of operational space stiffness and damping characteristics, which is crucial for robot-environment interactions. Additionally, since the reference is provided directly in operational space, complex inverse kinematics routines are unnecessary. However, disadvantages include the lack of formal stability guarantees—especially regarding the null-space dynamics—and the greater difficulty in considering actuator limits.

% In the following sections, we will generally define the control law as a function of the robot configuration $q$ and its time derivative $\dot{q}$ as the mapping into operational space through the forward kinematics $\chi = \pi(q,s)$ or into actuation coordinates through $\varphi = h(q)$ is usually always possible if needed. The same applies to the control reference, as discussed in the next paragraph.
In the following sections, we will generally define the control law as a function of the robot configuration $q$ and its time derivative $\dot{q}$, since mapping into operational space via the forward kinematics $\chi = \pi(q,s)$ or into actuation coordinates through $\varphi = h(q)$ is usually straightforward if needed. The same applies to the control reference, as discussed in the next paragraph.

\subsubsection{Taxonomy of Control Terms}
% Most controllers that we consider in this thesis can be separated into a feedforward term that leverages model knowledge and an error-based feedback term. 
% Specifically, a control law $\tau(t, q, \dot{q})$ can be decomposed into
Most controllers considered in this thesis consist of two components: either (a) a pure feedforward or mixed feedforward-feedback term that leverages model knowledge and (b) an error-based feedback term. Specifically, a control law $\tau(t, q, \dot{q})$ can be decomposed into
\begin{equation}
    \tau(t, q, \dot{q}, q^\mathrm{d},\dot{q}^\mathrm{d},\ddot{q}^\mathrm{d}) = \underbrace{\tau_\mathrm{mb}(t, q, \dot{q}, q^\mathrm{d},\dot{q}^\mathrm{d},\ddot{q}^\mathrm{d})}_\text{Model-Based} + \underbrace{\tau_\mathrm{fb}(t, q, \dot{q}, q^\mathrm{d},\dot{q}^\mathrm{d})}_\text{Error-Based Feedback}.
\end{equation}
% where $\tau_\mathrm{mb}(t, q, \dot{q}): \mathbb{R} \times \mathbb{R}^n \times \mathbb{R}^n \to \mathbb{R}^m$ is a model-based, not necessarily pure\footnote{A pure feedforward term would have the functional signature $\tau(t)$ as it only depends on the time-based reference $(q^\mathrm{d},\dot{q}^\mathrm{d})$ but not the current soft robot state $(q,\dot{q})$.}, feedforward term and $\tau_\mathrm{fb}(t, q, \dot{q})$ is a pure feedback term as it does not integrate any model knowledge.
Here, $\tau_\mathrm{mb}(t, q, \dot{q}): \mathbb{R} \times \mathbb{R}^n \times \mathbb{R}^n \to \mathbb{R}^m$ denotes a model-based term—not necessarily a pure feedforward\footnote{A pure feedforward term would have the signature $\tau(t)$, as it depends solely on the time-based reference $(q^\mathrm{d},\dot{q}^\mathrm{d})$ rather than the current soft robot state $(q,\dot{q})$.}—while $\tau_\mathrm{fb}(t, q, \dot{q})$ is an error-based feedback term that does not incorporate any model knowledge. To simplify the notation, we will in the following not explicitly state the dependence on the reference $(q^\mathrm{d},\dot{q}^\mathrm{d},\ddot{q}^\mathrm{d})$.

% In the following sections, we present various approaches for error-based feedback terms and model-based terms, respectively, that can be mostly relatively freely combined. Lastly, we showcase a few control approaches that integrate tightly the model-based terms and the feedback terms, such as a computed torque controller based on full feedback linearization and an operational space impedance controller.
In the following sections, we introduce a range of approaches for error-based feedback and model-based terms that can be combined quite flexibly. Finally, we highlight several control strategies that closely integrate these model-based and feedback components, including a computed torque controller based on full feedback linearization and an operational space impedance controller.

\subsection{Error-Based Feedback Terms}\label{sub:background:model_based_control:feedback_terms}
In this thesis, we consider the following formulation for an error-based feedback controller
\begin{equation}
    \tau_\mathrm{fb} = K_\mathrm{p} \left (\varphi_\mathrm{a}^\mathrm{d}(t) - \varphi_\mathrm{a}(t) \right ) + K_\mathrm{i} \int_0^t \sigma \left ( \varphi_{\mathrm{a}}^\mathrm{d}(t')-\varphi_{\mathrm{a}}(t') \right ) \: \mathrm{d} t' + K_\mathrm{d} \left ( \dot{\varphi}_\mathrm{a}^\mathrm{d}(t) - \dot{\varphi}_\mathrm{a}(t) \right ),
\end{equation}
where $K_\mathrm{p}, K_\mathrm{p}, K_\mathrm{d} \in \mathbb{R}^{m \times m}$ are control gain matrices, which we usually choose to be diagonal. 
% $\sigma(r): \mathbb{R}^m \to \mathbb{R}^m$ is a function to transform the control error $\varphi_{\mathrm{a}}^\mathrm{d}(t)-\varphi_{\mathrm{a}}(t)$ before integrating it.
% Based on this general formulation, we can devise several specific versions, which we introduce below.
$\sigma(r): \mathbb{R}^m \to \mathbb{R}^m$ is a function that transforms the control error $\varphi_{\mathrm{a}}^\mathrm{d}(t)-\varphi_{\mathrm{a}}(t)$ before integration. From this general formulation, we can derive several specific versions, which we outline below.

% \paragraph{PID Control.} A traditional PID controller can be easily recovered by setting the saturation function as the identity: $\sigma(r) = r$. We have considered such a feedback controller as a baseline in Chapters~\ref{chp:hsacontrol} \& \ref{chp:backstepping}.
\paragraph{PID Control.} A standard PID controller is obtained by setting the saturation function as the identity, i.e., $\sigma(r) = r$. We have used this feedback controller as a baseline in Chapters~\ref{chp:hsacontrol} and \ref{chp:backstepping}.

% \paragraph{PD Control.} A PD+~\citep{kelly1997pd}, as often used for the low-level control of rigid robots, can be realized by combining a PD controller with a compensation of static forces. The PD feedback term is simply implemented by choosing $K_\mathrm{i} = 0$.
\paragraph{PD Control.} The PD+ variant~\citep{kelly1997pd}, commonly employed for the low-level control of rigid robots, is realized by combining a PD controller with static force compensation. In practice, this is achieved by setting $K_\mathrm{i} = 0$.

% \paragraph{P-satI-D Control.} \citet{pustina2022p} has proposed an integral-saturated PID for shape regulation of soft robots via feedback control. A common choice for the saturated function is $\sigma(r) = \tanh(\gamma \, r)$, where $\gamma \in \mathbb{R}_+$ is a control gain to compress the control error before saturating it. We leverage this integral-saturated PID in Section~\ref{sec:hsacontrol:configuration_space_regulation} and Chapters~\ref{chp:pcsregression} \& \ref{chp:con}.
\paragraph{P-satI-D Control.} \citet{pustina2022p} introduced an integral-saturated PID for the shape regulation of soft robots via error-based feedback control. A typical choice for the saturation function is $\sigma(r) = \tanh(\gamma , r)$, where $\gamma \in \mathbb{R}_+$ is a control gain that compresses the control error prior to saturation. We implement this integral-saturated PID in Section~\ref{sec:hsacontrol:configuration_space_regulation} and Chapters~\ref{chp:pcsregression} and \ref{chp:con}.

\subsection{Model-Based Terms: The Fully Actuated Case}\label{sub:background:model_based_control:model_based_terms_fully_actuated}
% First, we consider common model-based terms for the fully actuated setting (i.e., $n = m$).
% Please note that for all controllers we introduce below, we assume that (1) the model is (reasonably) accurate or alternatively sufficiently large feedback gains are chosen (see high-gain control~\citep{marino1985high}), and (2) the integrability condition~\citep{pustina2024input} and mapping into actuation coordinates can be identified.
% Furthermore, (3) we assume here for the square matrix $A(q) \in \mathbb{R}^{n \times n}$ to be invertible for any $q \in \mathbb{R}^n$ or at locally in the relevant workspace.
% For the setpoint regulators, we additionally assume that (4) the setpoint $q^\mathrm{q}/\varphi^\mathrm{q}$ is an attainable equilibrium of the underactuated system~\citep{pustina2022feedback} - which means that it fulfills the property
% \begin{equation}
%     G(q^\mathrm{d}) + K(q^\mathrm{q}) = A(q^\mathrm{q}) \, \tau^\mathrm{ss},
% \end{equation}
% for a constant control action $\tau^\mathrm{ss}$, 
% (4) The system must be initialized within the reference’s region of attraction. For controllers for which \gls{GAS} can be proven, this condition is always met as such controllers are globally attractive.
% On the other hand, many controllers only exhibit \gls{LAS}. In this case, the region of attraction can often be enlarged by increasing the feedback gains, thereby enhancing the system’s stiffness~\citep{della2017controlling, della2023model}
% —or instead by canceling some of the non-convex potential forces via nonlinear feedback.
% (5) Additionally, the actuator needs to be fast enough in tracking its reference $(\mu^\mathrm{d}, \mu^\mathrm{d})$ so that we can approximate $\tau^\mathrm{d} \approx \tau(\mu,\dot{\mu})$, where $\tau^\mathrm{d}$ denotes the desired actuation/control input and $\tau(\mu,\dot{\mu})$ represents the actual forces, torques, currents, or pneumatic pressure generated.

% Finally, many of these controllers formulated in actuation coordinates have not been tested in simulation, and most have not yet been experimentally verified as the mapping into actuation coordinates was only very recently proposed~\citep{pustina2024input}.

First, we consider common model-based terms for the fully actuated setting (i.e., $n = m$). Please note that for all controllers introduced below, we assume that (1) the model is reasonably accurate—or that sufficiently high feedback gains are chosen (see high-gain control~\citep{marino1985high})—and (2) the integrability condition~\citep{pustina2024input} along with the mapping into actuation coordinates can be identified. Furthermore, (3) we assume that the square matrix $A(q) \in \mathbb{R}^{n \times n}$ is invertible for any $q \in \mathbb{R}^n$, at least locally within the relevant workspace.

For setpoint regulators, we additionally assume that (4) the setpoint $q^\mathrm{q}/\varphi^\mathrm{q}$ is an attainable equilibrium of the underactuated system~\citep{pustina2022feedback}—meaning it satisfies
\begin{equation}
    G(q^\mathrm{d}) + K(q^\mathrm{q}) = A(q^\mathrm{q}) \, \tau^\mathrm{ss},
\end{equation}
for a constant control action $\tau^\mathrm{ss}$—and that (5) the system is initialized within the reference’s region of attraction. For controllers where \gls{GAS} can be proven, this condition is inherently satisfied; however, many controllers only exhibit \gls{LAS}. In the latter case, the region of attraction can often be expanded by increasing the proportional feedback gains to enhance the system’s stiffness that comes with a loss of compliance~\citep{della2017controlling, della2023model} or by canceling some non-convex potential forces via nonlinear feedback. Additionally, (6) the actuator must be fast enough in tracking its reference $(\mu^\mathrm{d}, \mu^\mathrm{d})$ so that we can approximate $\tau^\mathrm{d} \approx \tau(\mu,\dot{\mu})$, where $\tau^\mathrm{d}$ denotes the desired actuation/control input and $\tau(\mu,\dot{\mu})$ represents the actual forces, torques, currents, or pneumatic pressure generated.

Finally, many controllers formulated in actuation coordinates have not yet been tested in simulation, and most have not been experimentally verified, as the mapping into actuation coordinates was only very recently proposed~\citep{pustina2024input}.

\subsubsection{Setpoint Regulation with Feedforward Compensation}
The following pure feedforward term regulates the system towards the setpoint $\varphi^\mathrm{d} = h(q^\mathrm{d})$ in actuation coordinates~\citep{kelly1994pd, borja2022energy, della2023model, pustina2025analysis}
\begin{equation}\label{eq:background:model_based_control:fully_actuated:potential_shaping_regulation}
    \tau_\mathrm{mb} = \partial_{\varphi} \mathcal{U}_\varphi(\varphi^\mathrm{d})  = A^{-1}(q^\mathrm{d}) \left ( G(q^\mathrm{d}) + K(q^\mathrm{d}) \right ).
\end{equation}
This controller with constant control input $\tau_\mathrm{mb}$ is often also referred to as an energy or potential shaping feedforward term~\citep{borja2022energy}.
% It can be seen how the constant model-based control input $\tau_\mathrm{mb}$ is a pure feedforward term.
Oftentimes, this pure feedforward term is complemented by a feedback controller that contains a PD-like term~\citep{della2023model}, e.g., $\tau_\mathrm{fb}(q,\dot{q}) = K_\mathrm{p} \left ( \varphi^\mathrm{d} - \varphi \right ) - K_\mathrm{d} \, \dot{\varphi}$, which renders the closed-loop dynamics to take the form
% This model-based feedforward term renders the closed-loop dynamics
\begin{equation}
    M_\varphi(q) \, \ddot{\varphi} + \eta_\varphi(q,\dot{q}) \, \dot{\varphi} + \partial_{\varphi} \mathcal{U}_\varphi(\varphi) - \partial_{\varphi} \mathcal{U}_\varphi(\varphi^\mathrm{d}) + K_\mathrm{p}  \left ( \varphi - \varphi^\mathrm{d} \right ) + \left ( D_\varphi(q) + K_\mathrm{d} \right ) \, \dot{\varphi} = 0_n.
\end{equation}
% to be locally asymptotically stable for a sufficiently large proportional feedback gain $K_\mathrm{p} > 0$.
As mentioned already before, for this regulator to be effective, $\varphi^\mathrm{d}$ needs to be an attainable equilibrium of the system.
The stability of the regulator can be demonstrated via the Lyapunov candidate~\citep{della2023model}
\begin{equation}\small
\begin{split}
    V(\varphi, \dot{\varphi}) =& \: \underbrace{\frac{1}{2} \, \dot{\varphi}^\top \, M_\varphi(h^{-1}(\varphi)) \, \dot{\varphi}}_\text{Kinetic Energy} + \underbrace{\mathcal{U}_{\varphi}(\varphi) - \mathcal{U}_{\varphi}(\varphi^\mathrm{d})}_\text{Centered Potential Energy}\\
    & \: + \underbrace{\left (G(h^{-1}(\varphi^\mathrm{d})) + K(h^{-1}(\varphi^\mathrm{d})) \right )^\top \, A^{-\top}(h^{-1}(\varphi^\mathrm{d})) \left ( \varphi^\mathrm{d} - \varphi \right )}_\text{Correction Term} + \underbrace{\frac{1}{2} \, (\varphi^\mathrm{d} - \varphi)^\top \, K_\mathrm{p} \, (\varphi^\mathrm{d} - \varphi)}_\text{Artificial Potential Energy of Feedback},
\end{split}
\end{equation}
which is a valid Lyapunov function - fulfilling the requirements $V(\varphi^\mathrm{d},0_n) = 0$ and $V(\varphi,\dot{\varphi}) > 0 \: \forall \: (\varphi, \dot{\varphi}) \in (\mathbb{R}^n, \mathbb{R}^n) \setminus \{ (\varphi^\mathrm{d}, 0_n) \}$ - if the closed-loop potential energy is locally or globally convex
\begin{equation}\small
    \frac{\partial^2}{\partial \varphi^2} \mathcal{U}_{\varphi}(\varphi) \bigg |_\mathrm{\varphi = \varphi^\mathrm{d}} + K_\mathrm{p} = \frac{\partial}{\partial \varphi} \left (  A^{-1}(h^{-1}(\varphi)) \,  \left ( G(h^{-1}(\varphi)) + K(h^{-1}(\varphi)) \right ) \right ) \bigg |_\mathrm{\varphi = \varphi^\mathrm{d}} + K_\mathrm{p} \succ 0.
\end{equation}
The Lyapunov function exhibits the time derivative~\citep{della2023model}
\begin{equation}\small
\begin{split}
    \dot{V}(\varphi,\dot{\varphi}) 
    =& \: \dot{\varphi}^\top \, M_\varphi(h^{-1}(\varphi)) \, \ddot{\varphi} + \frac{1}{2} \, \dot{\varphi}^\top \, \dot{M}_\varphi(h^{-1}(\varphi)) \, \dot{\varphi} - \dot{\varphi}^\top \, \left ( \partial_{\varphi} \mathcal{U}_\varphi(\varphi) - \partial_{\varphi} \mathcal{U}_\varphi(\varphi^\mathrm{d}) + K_\mathrm{p} \left ( \varphi - \varphi^\mathrm{d} \right ) \right ),\\
    =& \: -\dot{\varphi}^\top \, \eta_\varphi(q,\dot{q}) \, \dot{\varphi} + \frac{1}{2} \, \dot{\varphi}^\top \, \dot{M}_\varphi(q) \, \dot{\varphi} + \dot{\varphi}^\top \left ( D_\varphi(h^{-1}(\varphi)) + K_\mathrm{d} \right ) \, (-\dot{\varphi}),\\
    =& \: -\dot{\varphi}^\top \, \left ( D_\varphi(h^{-1}(\varphi)) + K_\mathrm{d} \right ) \, \dot{\varphi} \leq 0 \quad \forall \: \varphi,\dot{\varphi} \in \mathbb{R}^n.
\end{split}
\end{equation}
Finally, as $\dot{V}(\dot{\varphi}) \leq 0 \: \forall \: \varphi,\dot{\varphi}\in \mathbb{R}^n$, asymptotic stability can be proven via LaSalle's invariance theorem~\citep{khalil2002nonlinear} as $\varphi^\mathrm{d}$ is a static equilibrium of the closed-loop system.

In the following, we will discuss the stability properties of the controller in more detail.
If the open-loop potential energy of the soft robot, consisting of elastic and gravitational terms, is globally convex
\begin{equation}
    \frac{\partial^2}{\partial \varphi^2} \mathcal{U}_{\varphi}(\varphi) \bigg |_\mathrm{\varphi = \varphi^\mathrm{d}} = \frac{\partial}{\partial \varphi} \left (  A^{-1}(h^{-1}(\varphi)) \,  \left ( G(h^{-1}(\varphi)) + K(h^{-1}(\varphi)) \right ) \right ) \bigg |_\mathrm{\varphi = \varphi^\mathrm{d}} \succ 0, 
\end{equation}
what is sometimes also referred to as the soft robot being \emph{elastically dominated}~\citep{borja2022energy, della2023model, pustina2025analysis}. This means that the robot is considered to be relatively stiff and able to withstand gravity. In such case, the proportional feedback term is not strictly necessary (i.e., we can set $K_\mathrm{p} = 0_{n \times n}$, and $\varphi^\mathrm{d}$ is still an asymptotically stable equilibrium of the closed-loop system.
In turn, when the open-loop potential energy of the soft robot is non-convex, we can still stabilize the system locally or even globally by choosing sufficiently large proportional feedback gains $K_\mathrm{p} \succ 0$.
This, however, comes at the cost of increased system stiffness, reduced compliance, and enlarged risk of instability because of measurement noise.
A derivative feedback term is not necessary as for soft robots generally $D\varphi(\varphi) \succ 0 \: \forall \: \varphi \in \mathbb{R}^n$. Still, we can increase dissipation by choosing $K_\mathrm{d} \succ 0$.

We leverage such a potential shaping feedforward term in Chapters~\ref{chp:hsacontrol}, \ref{chp:pcsregression}-\ref{chp:con} of this thesis.
The controller exhibits great robustness to modeling errors and measurement noise.
Also, it is computationally extremely efficient as the controller only needs to be evaluated once per setpoint.
However, this comes at the cost of the necessity for increased feedback gains to ensure (global) convergence. Also, exponential convergence is not guaranteed.

% In the following, we will discuss the convergence guarantees in more detail.

% \textbf{Convex Potential Field.} If the potential field is convex (i.e., $\frac{\partial^2}{\partial \varphi^2}  \mathcal{U}_\varphi(\varphi) \succ 0 \: \forall \varphi \in \mathbb{R}$) this controller is globally asymptotically stable - even with a deactivated feedback term $\tau_\mathrm{fb}(t,q,\dot{q})=0$.

% \textbf{Constant Actuation Matrix and Elastic Domination.} Another interesting case is the one of a constant actuation matrix $A(q) = A$ and elastic domination with $\frac{\partial K(q)}{\partial q} + $

%  If this is not the case, the region of attraction can be increased, or the controller can even be made globally asymptotically stable by sufficiently increasing the proportional gains $K_\mathrm{p}$ of the feedback controller, which makes the system stiffer and more susceptible to instability because of measurement errors.

\subsubsection{Setpoint Regulation with Gravity Cancellation and Compensation of Elastic Forces}
% In case the elastic potential is convex, but the gravitational potential renders the total potential energy to be non-convex, we can reduce the necessary (proportional) feedback gains, compared to the \emph{Setpoint Regulation with Feedforward Compensation} controller, by canceling instead of compensating the gravitational forces. 
When the elastic potential is convex but the gravitational potential makes the overall potential energy non-convex, we can lower the required (proportional) feedback gains—compared to the \emph{Setpoint Regulation with Feedforward Compensation} controller—by canceling rather than compensating for the gravitational forces.
The control law is then given as~\citep{della2020model}
\begin{equation}
    \tau_\mathrm{mb}(q) =  \underbrace{A^{-1}(q) \, G(q)}_\text{Cancel Gravity} + \underbrace{A^{-1}(q^\mathrm{d}) \, K(q^\mathrm{d})}_\text{Comp. Elasticity},
\end{equation}
leading to the closed-loop dynamics
\begin{equation}
    M_\varphi(q) \, \ddot{\varphi} + \eta_\varphi(q,\dot{q}) \, \dot{\varphi} + A^{-1}(q) \,  K(q) - A^{-1}(q^\mathrm{d}) \, K(q^\mathrm{d}) + D_\varphi(q) \, \dot{\varphi} = \tau_\mathrm{fb}(t, q, \dot{q}),
\end{equation}
which we can rewrite, assuming that a PD term is part of the feedback as
\begin{equation}\footnotesize
    M_\varphi(q) \, \ddot{\varphi} + \eta_\varphi(q,\dot{q}) \, \dot{\varphi} + A^{-1}(h^{-1}(\varphi)) \,  K(h^{-1}(\varphi)) - A^{-1}(h^{-1}(\varphi^\mathrm{d})) \, K(h^{-1}(\varphi^\mathrm{d})) + K_\mathrm{p} \left ( \varphi-\varphi^\mathrm{d} \right ) + \left ( D_\varphi(q) + K_\mathrm{d} \right ) \, \dot{\varphi} = 0_n,
\end{equation}
which is asymptotically stable if the elastic potential $\mathcal{U}_{\varphi,\mathrm{K}}(\varphi)$ is locally or globally convex
\begin{equation}\label{eq:background:model_based_control:fully_actuated:regulation_gravity_cancellation:closed_loop_potential_convexity}
    \frac{\partial^2}{\partial \varphi^2} \mathcal{U}_{\varphi,\mathrm{K}}(\varphi) \bigg |_\mathrm{\varphi = \varphi^\mathrm{d}} + K_\mathrm{p} = \frac{\partial}{\partial \varphi} \left (  A^{-1}(h^{-1}(\varphi)) \,  K(h^{-1}(\varphi)) \right ) \bigg |_\mathrm{\varphi = \varphi^\mathrm{d}} + K_\mathrm{p} \succ 0.
\end{equation}
This can be shown via the Lyapunov function~\citep{khalil2002nonlinear, della2020model, della2023model}
\begin{equation}
\begin{split}
    V(\varphi, \dot{\varphi}) =& \: \underbrace{\frac{1}{2} \, \dot{\varphi}^\top \, M_\varphi(h^{-1}(\varphi)) \, \dot{\varphi}}_\text{Kinetic Energy} + \underbrace{\mathcal{U}_{\varphi,\mathrm{K}}(\varphi) - \mathcal{U}_{\varphi,\mathrm{K}}(\varphi^\mathrm{d})}_\text{Centered Elastic Potential Energy}\\
    & \: + \underbrace{K^\top(h^{-1}(\varphi^\mathrm{d})) \, A^{-\top}(h^{-1}(\varphi^\mathrm{d})) \left ( \varphi^\mathrm{d} - \varphi \right )}_\text{Correction Term} + \underbrace{\frac{1}{2} \, (\varphi^\mathrm{d} - \varphi)^\top \, K_\mathrm{p} \, (\varphi^\mathrm{d} - \varphi)}_\text{Artificial Potential Energy of Feedback},
\end{split}
\end{equation}
with the associated time derivative~\citep{della2023model}
\begin{equation}
    \dot{V}(\varphi, \dot{\varphi}) = -\dot{\varphi}^\top \, \left ( D_\varphi(h^{-1}(\varphi)) + K_\mathrm{d} \right ) \, \dot{\varphi} \leq 0 \quad \forall \: \varphi,\dot{\varphi} \in \mathbb{R}^n
\end{equation}
If the condition from Eq.~\ref{eq:background:model_based_control:fully_actuated:regulation_gravity_cancellation:closed_loop_potential_convexity} is locally met for $\varphi = \varphi^\mathrm{d}$, then the setpoint $\varphi^\mathrm{d}$ is locally asymptotically stable. If the convexity condition is met $\forall \: \varphi \in \mathbb{R}^n$, then the setpoint is globally asymptotically stable.
% which are locally asymptotically stable with a sufficiently large proportional feedback gain $K_\mathrm{p} > 0$~\citep{pustina2025analysis}.

Here, it is easy to see how the proportional feedback gain makes the robot stiffer and, with that, can potentially allow for the system to be stable even when the open-loop elastic potential is non-convex. Still, this comes at the cost of decreased compliance and decreased robustness against measurement noise.
In the case of the actuation space elastic potential being convex, i.e., $\frac{\partial}{\partial \varphi} \left (A^{-1}(h^{-1}(\varphi)) \,  K(h^{-1}(\varphi)) \right ) \succ 0$, then the proportional feedback gains are not necessary and can also be chosen as zero.
An interesting case is also when (i) a constant actuation matrix $A(q) = A$, which is, for example, the case for many pneumatically-actuated soft robots, together with (ii) and a convex configuration space elastic potential, as for example the case for linear elasticity $K(q) = S \, q$, where $S\succ 0$. Then, the closed-loop dynamics are given by
\begin{equation}
    M_\varphi(q) \, \ddot{\varphi} +  \eta_\varphi(q,\dot{q}) \, \dot{\varphi} + S_\varphi ( \varphi - \varphi^\mathrm{d} ) + D_\varphi \, \dot{\varphi} = \tau_\mathrm{fb}(t, q, \dot{q}),
\end{equation}
which renders $\varphi^\mathrm{d}$ to be globally asymptotically stable.
We leverage such a controller in Chapter~\ref{chp:hsacontrol} of this thesis.

% This controller is particularly interesting in the case of (i) a constant actuation matrix $A(q) = A$, which is, for example, the case for many pneumatically-actuated soft robots, together with (ii) and a convex elastic potential, as for example the case for $K(q) = S \, q$, where $S\succ 0$, as then the closed-loop dynamics
% \begin{equation}
%     M_\varphi(q) \, \ddot{\varphi} + \eta_\varphi(q,\dot{q}) \, \dot{\varphi} + A^{-1} \left ( K(q) - K(q^\mathrm{d}) \right ) + D_\varphi \, \dot{\varphi} = \tau_\mathrm{fb}(t, q, \dot{q}),
% \end{equation}
% exhibit a globally asymptotically stable equilibrium at the setpoint $q^\mathrm{d}$, even when the soft robot is not elastically dominated.

\subsubsection{Setpoint Regulation with Cancellation of Static Forces}
Akin to PD+~\citep{kelly1996class, kelly1998global} controllers originally developed for rigid manipulators, we can fully cancel the static, including gravitational and elastic, forces of the soft robot dynamics via nonlinear feedback and achieve setpoint regulation solely based on the potential field established by the (proportional) feedback term. The associated control law is given by~\citep{patterson2024design, pustina2025analysis}
\begin{equation}
    \tau_\mathrm{mb}(q) =  \underbrace{A^{-1}(q) \, G(q)}_\text{Cancel Gravity} + \underbrace{A^{-1}(q) \, K(q)}_\text{Cancel Elasticity}
\end{equation}
which results in the closed-loop dynamics
\begin{equation}
    M_\varphi(q) \, \ddot{\varphi} + \eta_\varphi(q,\dot{q}) \, \dot{\varphi} + D_\varphi(q) \, \dot{\varphi} = \tau_\mathrm{fb}(t, q, \dot{q}),
\end{equation}
where the potential of the system is now fully dominated by the feedback controller.
Such a closed-loop system with a proportional feedback term, for example,
\begin{equation}
    M_\varphi(q) \, \ddot{\varphi} + \eta_\varphi(q,\dot{q}) \, \dot{\varphi} +  K_\mathrm{p} ( \varphi - \varphi^\mathrm{d}) + D_\varphi(q) \, \dot{\varphi} = 0_n,
\end{equation}
is for any positive proportional gain $K_\mathrm{p} \succ 0 \in \mathbb{R}^{n \times n}$ globally asymptotically stable - even for small gains.
This can be proven using the Lyapunov function
\begin{equation}
    V(\varphi,\dot{\varphi}) = \frac{1}{2} \, \dot{\varphi}^\top \, M_\varphi(h^{-1}(\varphi)) \, \dot{\varphi} + \frac{1}{2} \, \left (\varphi - \varphi^\mathrm{d} \right )^\top \, K_\mathrm{p} \, \left (\varphi - \varphi^\mathrm{d} \right ),
\end{equation}
that exhibits an associated time derivative of
\begin{equation}
    \dot{V}(\varphi, \dot{\varphi}) = - \dot{\varphi}^\top \, D_\varphi(h^{-1}(\varphi))) \, \dot{\varphi} \leq 0 \quad \forall \varphi, \dot{\varphi} \in \mathbb{R}^n,
\end{equation}
as $D_\varphi(h^{-1}(\varphi))) \succ 0 \: \forall \: \varphi \in \mathbb{R}^n$. 
% Via LaSalle's invariance principle, \gls{GAS} with respect to the equilibrium $\varphi^\mathrm{d}$ can be shown~\citep{khalil2002nonlinear}.
% This strength of global convergence guarantees even for configuration-dependent actuation matrices $A(q)$ comes potentially at the cost of robustness as, particularly for low feedback gains $K_\mathrm{p}$, unmodelled system dynamics could become dominant, causing steady-state errors or even instability.
By applying LaSalle’s invariance principle, \gls{GAS} with respect to the equilibrium $\varphi^\mathrm{d}$ can be established~\citep{khalil2002nonlinear}. However, this guarantee of global convergence—even for configuration-dependent actuation matrices $A(q)$—may come at the expense of robustness. In particular, with low proportional feedback gains $K_\mathrm{p}$, unmodeled system dynamics might dominate, leading to steady-state errors or even instability.

\subsubsection{Trajectory Tracking with Feedforward Compensation}
In the following, we will assume the actuation matrix to be constant with $A(q) = A$. Then, extending the previously presented setpoint regulator with feedforward compensation, we can design a trajectory tracking algorithm with feedforward compensation as~\citep{kelly1994pd, della2023model}
\begin{equation}
    \tau_\mathrm{mb}(t) =  \underbrace{M_\varphi(q^\mathrm{d}(t)) \, \ddot{\varphi}^\mathrm{d}(t) + \eta_\varphi(q^\mathrm{d}(t),\dot{q}^\mathrm{d}(t)) \, \dot{\varphi}^\mathrm{d}(t) + D_\varphi \, \dot{q}^\mathrm{d}(t)}_\text{Compensate Dynamic Forces} + \underbrace{ A^{-1} \big ( G(q^\mathrm{d}(t)) + K(q^\mathrm{d}(t)) \big )}_\text{Compensate Static Forces}.
\end{equation}
% This model-based feedforward term generates the closed-loop dynamics
% \begin{equation}
%     M_\varphi(q) \, \ddot{\varphi} + \eta_\varphi(q,\dot{q}) \, \dot{q} + \partial_{\varphi} \mathcal{U}_\varphi(\varphi) - \partial_{\varphi} \mathcal{U}_\varphi(\varphi^\mathrm{d}) + D_\varphi(q) \, \dot{q} = \tau_\mathrm{fb}(t, q, \dot{q}),
% \end{equation}
% After defining $e(t) = q^\mathrm{d}(t) - q(t)$, $e(t) = q^\mathrm{d}(t) - q(t)$
% to be locally asymptotically stable \textcolor{orange}{for a sufficiently large proportional feedback gain $K_\mathrm{p} > 0$}.
This controller is locally asymptotically stable, assuming sufficiently large proportional and dissipative feedback gains $K_\mathrm{p}, K_\mathrm{d} \succ 0$.
We refer the interested reader to \citet{kelly1994pd, della2023model} for the full proof.
The advantages and disadvantages mirror the ones of the \emph{Setpoint Regulation with Feedforward Compensation} controller: robust against modeling errors and measurement noise and requires relatively high error-based feedback gains that come with a loss of compliance.

\subsubsection{Trajectory Tracking with Mixed State Feedback}
% In the following, we will assume the actuation matrix to be constant with $A(q) = A$.
% Additionally, as this controller is particularly interesting for soft robots with convex elastic potential, we assume linear elasticity $K(q) = S \, q$ with $S \succ 0$, although the controller would also converge globally for any convex potential field or locally for non-convex elastic potentials assuming sufficiently large feedback gains. We refer the interested reader to the section on \emph{Setpoint Regulation with Gravity Cancellation and Compensation of Elastic Forces} for an extended discussion on this topic.
In the following, we assume that the actuation matrix is constant, i.e., $A(q) = A$. Moreover, since this controller is particularly well-suited for soft robots with a convex elastic potential, we assume linear elasticity $K(q) = S \, q$ with $S \succ 0$. Note that the controller would still converge globally for any convex potential field—or locally for non-convex elastic potentials provided sufficiently high feedback gains are used. For a more detailed discussion, please refer to the section on \emph{Setpoint Regulation with Gravity Cancellation and Compensation of Elastic Forces}.

% A trajectory tracking controller that exhibits full state feedback apart from compensating instead of canceling elastic forces is given by~\citep{kelly1996class, della2020model}
A trajectory tracking controller that employs full state feedback, except for compensating instead of canceling elastic forces, can be formulated as~\citep{kelly1996class, della2020model}
\begin{equation}
    \tau_\mathrm{mb}(t,q,\dot{q}) = \underbrace{M_\varphi(q(t)) \, \ddot{\varphi}^\mathrm{d}(t) + \eta_\varphi(q(t),\dot{q}(t)) \, \dot{\varphi}^\mathrm{d}(t) + A^{-1} \, G(q(t))}_\text{Rigid Manipulator Nonlinear PD/PD+} + \underbrace{S_\varphi \, \varphi^\mathrm{d}(t) + D_\varphi \, \dot{\varphi}^\mathrm{d}(t)}_\text{Shaping Soft Robot Impedance},
\end{equation}
where $S_\varphi = A^{-1} \, S \, A^{-\top} \succ 0 \in \mathbb{R}^{n \times n}$.
This leads to the closed-loop dynamics
\begin{equation}\footnotesize
    M_\varphi(q(t)) \, \left ( \ddot{\varphi}(t) - \ddot{\varphi}^\mathrm{d}(t) \right ) + \eta_\varphi(q(t),\dot{q}(t)) \left ( \dot{\varphi}(t) - \dot{\varphi}^\mathrm{d}(t) \right ) + S_\varphi \left ( \varphi(t) - \varphi^\mathrm{d}(t) \right ) + D_\varphi \left ( \dot{\varphi}(t) - \dot{\varphi}^\mathrm{d}(t) \right ) = \tau_\mathrm{fb}(t,q,\dot{q}).
\end{equation}
% which we can rewrite as
% \begin{equation}\small
%     M_\varphi(q(t)) \, \left ( \ddot{\varphi}(t) - \ddot{\varphi}^\mathrm{d}(t) \right ) + \left ( \eta_\varphi(q(t),\dot{q}(t)) + D_\varphi \right ) \, \left ( \dot{\varphi}(t) - \dot{\varphi}^\mathrm{d}(t) \right ) + A^{-1} \left ( K(A^{-\top} \varphi(t)) - K(A^{-\top} \varphi^\mathrm{d}(t)) \right ) = \tau_\mathrm{fb}(t,q,\dot{q}).
% \end{equation}
The goal is now to show that the closed-loop error dynamics, which are defined as
\begin{equation}
    M_\varphi(q(t)) \, \ddot{e}(t) + \left ( \eta_\varphi(q(t),\dot{q}(t)) + D_\varphi \right ) \, \dot{e}(t) + S_\varphi \, e(t) = \tau_\mathrm{fb}(t,q,\dot{q}),
\end{equation}
with $e(t) = \varphi(t) - \varphi^\mathrm{d}(t) \in \mathbb{R}^n$, $\dot{e}(t) = \dot{\varphi} - \dot{\varphi}^\mathrm{d}(t)$, and $\ddot{e}(t) = \ddot{\varphi}(t) - \ddot{\varphi}^\mathrm{d}(t)$ asymptotically converge to zero: $\lim_{t \to \infty} e(t) = 0$.
Even without an error-based feedback term (i.e., $\tau_\mathrm{fb}(t,q,\dot{q}) = 0$), the asymptotic convergence to the trajectory $(\varphi^\mathrm{d}, \dot{\varphi}^\mathrm{d}$ can be shown via the Lyapunov function
\begin{equation}
    V(e, \dot{e}) = \frac{1}{2} \, \dot{e}^\top \, M_\varphi(h^{-1}(\varphi^\mathrm{d}+e) \, \dot{e}(t) + \frac{1}{2} \, e^\top(t) \, \left ( S_\varphi + K_\mathrm{d} \right ) \, e(t),
\end{equation}
that exhibits the time derivative
\begin{equation}
    \dot{V}(\dot{e}) = -\dot{e}^\top \left (D_\varphi + K_\mathrm{d} \right ) \, \dot{e} \leq 0 \quad \forall \: \dot{e} \in \mathbb{R}^n,
\end{equation}
by applying Barbalat's Lemma~\citep{slotine1991applied, della2020model}.
Here, $K_\mathrm{p}, K_\mathrm{d} \in \mathbb{R}^{n \times n} \succeq 0$ are any PD feedback gains that are optionally applied.
% This is locally the case for sufficiently large proportional and dissipative feedback gains $K_\mathrm{p} > 0$. Alternatively, if (a) the elastic potential is convex, which is typically the case for most soft robots, and (b) the damping matrix is in actuation coordinates . Specifically, the elastic potential needs to meet the condition $\frac{\partial^2 \mathcal{U}_\varphi (\varphi)}{\partial \varphi^2} = \frac{\partial K(A^\top \varphi)}{\partial \varphi} \succ 0$. For linear elastic systems with $K(\varphi) = S \, A^{-\top} \varphi$, this is the case when $S \, A^{-\top} \succ 0$.


\subsection{Model-Based Terms: The Underactuated Case}\label{sub:background:model_based_control:model_based_terms_underactuated}

\subsubsection{Preliminaries}

In the following, we will consider the underactuated where $m < n$. As underactuation is not a primary focus of this thesis, we will only broach the subject. For a much more detailed discussion, we refer the interested reader to the seminal thesis by \citet{pustina2025analysis}.

First, we need to revisit the definition of attainable equilibria.
In the case of underactuated soft robots, a setpoint $\varphi^\mathrm{d} = \begin{bmatrix}
    \varphi_\mathrm{a}^{\mathrm{d}^\top} & \varphi_\mathrm{u}^{\mathrm{d}^\top}
\end{bmatrix}^\top = h(q^\mathrm{d})$, where $q^\mathrm{d} = \begin{bmatrix}
    q_\mathrm{a}^{\mathrm{d}^\top} & q_\mathrm{u}^{\mathrm{d}^\top}
\end{bmatrix}^\top$, needs to be a solution to the equilibrium equation~\citep{pustina2025analysis}
\begin{equation}
    \begin{bmatrix}
        A_\mathrm{a}^{-1}(q^\mathrm{d}) \, \left ( G_\mathrm{a}(q^\mathrm{d}) + K_\mathrm{a}(q^\mathrm{d}) \right )\\
        -A_\mathrm{u}(q^\mathrm{d}) \, A_\mathrm{a}^{-1}(q^\mathrm{d}) \left ( G_\mathrm{a}(q^\mathrm{d}) + K_\mathrm{a}(q^\mathrm{d}) \right ) + G_\mathrm{u}(q^\mathrm{d}) + K_\mathrm{u}(q^\mathrm{d})
    \end{bmatrix} = \begin{bmatrix}
        \tau^\mathrm{ss}\\
        0_{n-m}
    \end{bmatrix}.
\end{equation}

\subsubsection{Zero Dynamics in the Regulation Case}
It is essential for the stability of the system to ensure that the zero dynamics of the system, i.e., the last $n-m$, unactuated \glspl{DOF} of the closed-loop dynamics, remain bounded. If the zero dynamics are unstable, the system state will eventually diverge, even if initial stability is observed from an input-output perspective~\citep{pustina2025analysis}.
For a regulator, that drives the system towards $\varphi = \varphi^\mathrm{d}, \dot{\varphi} = 0$, the associated zero dynamics are given as~\citep{pustina2025analysis}
\begin{equation}
    M_{\varphi,\mathrm{uu}}(q^{\mathrm{d}_\mathrm{a}}) \, \ddot{\varphi}_\mathrm{u} + \eta_{\varphi,\mathrm{u}}(q^{\mathrm{d}_\mathrm{a}},\dot{q}^{\mathrm{d}_\mathrm{a}}) \, \dot{\varphi}_\mathrm{u} + \partial_{\varphi_\mathrm{u}} \mathcal{U}_\varphi(\varphi^{\mathrm{d}_\mathrm{a}}) + D_{\varphi,\mathrm{uu}}(q^{\mathrm{d}_\mathrm{a}}) \, \dot{\varphi}_\mathrm{u} = 0_{n-m}
\end{equation}
where $q^{\mathrm{d}_\mathrm{a}} = \begin{bmatrix}
    q_\mathrm{a}^{\mathrm{d}^\top} & q_\mathrm{u}^{\top}
\end{bmatrix}^\top$, $\dot{q}^{\mathrm{d}_\mathrm{a}} = \begin{bmatrix}
    0_m^\top & \dot{q}_\mathrm{u}^{\top}
\end{bmatrix}^\top$, and $\varphi^{\mathrm{d}_\mathrm{a}} = \begin{bmatrix}
    \varphi_\mathrm{a}^{\mathrm{d}^\top} & \varphi_\mathrm{u}^{\top}
\end{bmatrix}^\top$.
The Lyapunov function
\begin{equation}
    V(\varphi_\mathrm{u},\dot{\varphi}_\mathrm{d}) = \frac{1}{2} \, \dot{\varphi}_\mathrm{u}^\top \, M_{\varphi,\mathrm{uu}}(h^{-1}(\varphi^{\mathrm{d}_\mathrm{a}})) \, \dot{\varphi}_\mathrm{u} + \mathcal{U}_\varphi(\varphi^{\mathrm{d}_\mathrm{a}})),
\end{equation}
that is non-negative provided that both the elastic and gravitational forces are Lipschitz and upper-bounded in their magnitude~\citep{pustina2025analysis}, exhibits the time derivative
\begin{equation}
    \dot{V}(\varphi_\mathrm{u},\dot{\varphi}_\mathrm{u}) = -\dot{\varphi}_\mathrm{u}^\top \, D_{\varphi,\mathrm{uu}}(q^{\mathrm{d}_\mathrm{a}}) \, \dot{\varphi}_\mathrm{u} \leq 0 \quad \forall \:  q^{\mathrm{d}_\mathrm{a}} \in \mathbb{R}^{n}, \dot{\varphi}_\mathrm{u} \in \mathbb{R}^{n-m},
\end{equation}
as $D_{\varphi,\mathrm{uu}}(q^{\mathrm{d}_\mathrm{a}}) \succ 0$.
Subsequently, it can be shown that these zero dynamics are bounded and converge to $(\varphi_\mathrm{u},\dot{\varphi}_\mathrm{u}) = (\varphi_\mathrm{u}^\mathrm{d}, 0)$~\citep{pustina2025analysis}, where $\varphi_\mathrm{u}^\mathrm{d}$ is a solution to
\begin{equation}\footnotesize
    \frac{\partial }{\partial \varphi_\mathrm{u}} \mathcal{U}_\varphi \left ( \begin{bmatrix}
        \varphi_\mathrm{a}^\mathrm{d}\\ \varphi_\mathrm{u}^\mathrm{d}
    \end{bmatrix} \right ) = -A_\mathrm{u}(h^{-1}(\varphi^\mathrm{d})) \, A_\mathrm{a}^{-1}(h^{-1}(\varphi^\mathrm{d})) \left ( G_\mathrm{a}(h^{-1}(\varphi^\mathrm{d})) + K_\mathrm{a}(h^{-1}(\varphi^\mathrm{d}) \right ) + G_\mathrm{u}(h^{-1}(\varphi^\mathrm{d})) + K_\mathrm{u}(h^{-1}(\varphi^\mathrm{d}) = 0_{n-m}.
\end{equation}

\subsubsection{Setpoint Regulation with Feedforward Compensation}
A setpoint regulator with feedforward compensation that shapes the potential of the actuated coordinates is given by~\citep{pustina2025analysis}
\begin{equation}
    \tau_\mathrm{mb} = \frac{\partial \mathcal{U}_\varphi(\varphi)}{\partial \varphi_\mathrm{a}} \bigg |_{\varphi=\varphi^\mathrm{d}} = A_\mathrm{a}^{-1}(q^\mathrm{d}) \, \left ( G_\mathrm{a}(q^\mathrm{d}) + K_\mathrm{a}(q^\mathrm{d}) \right ),
\end{equation}
leading to the closed-loop dynamics
\begin{equation}\scriptsize
    M_\varphi(q) \, \ddot{\varphi} + \begin{bmatrix}
        \eta_{\varphi,\mathrm{a}}(q,\dot{q})\\ \eta_{\varphi,\mathrm{u}}(q,\dot{q})
    \end{bmatrix} \, \dot{\varphi} + \begin{bmatrix}
        A_\mathrm{a}^{-1}(q) \left ( G_\mathrm{a}(q) + K_\mathrm{a}(q) \right ) - A_\mathrm{a}^{-1}(q^\mathrm{d}) \left ( G_\mathrm{a}(q^\mathrm{d}) + K_\mathrm{a}(q^\mathrm{d}) \right ) + K_\mathrm{p} \left ( \varphi_\mathrm{a} - \varphi^\mathrm{d}_\mathrm{a} \right ) + K_\mathrm{d} \, \dot{\varphi}_\mathrm{a}\\
        -A_\mathrm{u}(q) \, A_\mathrm{a}^{-1}(q) \left ( G_\mathrm{a}(q) + K_\mathrm{a}(q) \right ) + G_\mathrm{u}(q) + K_\mathrm{u}(q)
    \end{bmatrix} + \begin{bmatrix}
        D_{\varphi,\mathrm{a}}(q)\\
        D_{\varphi,\mathrm{u}}(q)
    \end{bmatrix} \, \dot{\varphi} = \begin{bmatrix}
        0_m\\ 0_{n-m}
    \end{bmatrix},
\end{equation}
where we assumed that the feedback controller $\tau_\mathrm{fb}(\varphi,\dot{\varphi})$ contains a PD with gains $K_\mathrm{p}, K_\mathrm{d} \in \mathbb{R}^{m \times m}$.
These closed-loop dynamics are equivalent to
\begin{equation}\scriptsize
    \begin{bmatrix}
        M_{\varphi,\mathrm{aa}}(q) & M_{\varphi,\mathrm{au}}(q)\\ 
        M_{\varphi,\mathrm{ua}}(q) & M_{\varphi,\mathrm{uu}}(q)
    \end{bmatrix} \, \ddot{\varphi} + \begin{bmatrix}
        \eta_{\varphi,\mathrm{a}}(q,\dot{q})\\ \eta_{\varphi,\mathrm{u}}(q,\dot{q})
    \end{bmatrix} \, \dot{\varphi} + \begin{bmatrix}
       \partial_{\varphi_\mathrm{a}} \mathcal{U}_\varphi(\varphi) - \partial_{\varphi_\mathrm{a}} \mathcal{U}_\varphi(\varphi^\mathrm{d}) + K_\mathrm{p} \left ( \varphi_\mathrm{a} - \varphi^\mathrm{d}_\mathrm{a} \right ) + K_\mathrm{d} \, \dot{\varphi}_\mathrm{a}\\
       \partial_{\varphi_\mathrm{u}} \mathcal{U}_\varphi(\varphi)
    \end{bmatrix} + \begin{bmatrix}
        D_{\varphi,\mathrm{a}}(q)\\
        D_{\varphi,\mathrm{u}}(q)
    \end{bmatrix} \, \dot{\varphi} = \begin{bmatrix}
        0_m\\ 0_{n-m}
    \end{bmatrix}.
\end{equation}
We can devise the Lyapunov candidate
\begin{equation}
\begin{split}
    V(\varphi, \dot{\varphi}) =& \: \underbrace{\frac{1}{2} \, \dot{\varphi}^\top \, M_\varphi(h^{-1}(\varphi)) \, \dot{\varphi}}_\text{Kinetic Energy} + \underbrace{\mathcal{U}_\varphi(\varphi) - \mathcal{U}_\varphi(\varphi^\mathrm{d})}_\text{Centered Potential Energy}\\
    & \: + \underbrace{\frac{\partial \mathcal{U}_\varphi(\varphi)}{\partial \varphi_\mathrm{a}} \Bigg |_{\varphi = \varphi^\mathrm{d}}^\top \left ( \varphi_\mathrm{a}^\mathrm{d} - \varphi_\mathrm{a} \right )}_\text{Correction Term on Actuated Coord.} + \underbrace{\frac{1}{2} \, (\varphi_\mathrm{a}-\varphi_\mathrm{a}^\mathrm{d})^\top \, K_\mathrm{p} \, (\varphi_\mathrm{a}-\varphi_\mathrm{a}^\mathrm{d})}_\text{Artificial Potential Energy},
\end{split}
\end{equation}
which is valid if
\begin{equation}
    \frac{\partial^2 \mathcal{U}_\varphi(\varphi)}{\partial \varphi^2} \Bigg |_{\varphi = \varphi^\mathrm{d}} + \begin{bmatrix}
        K_\mathrm{p} & 0_{m \times (n-m)}\\
        0_{(n-m) \times m} & 0_{(n-m) \times (n-m)}
    \end{bmatrix} \succ 0,
\end{equation}
which can be locally ensured by choosing $K_\mathrm{p} \succ 0$ sufficiently large~\citep{pustina2025analysis}.
The time derivative of the Lyapunov function is given as
\begin{equation}
\begin{split}
    \dot{V}(\varphi,\dot{\varphi}) 
    % =& \: \dot{\varphi}^\top \, M_\varphi(h^{-1}(\varphi)) \, \ddot{\varphi} + \frac{1}{2} \, \dot{\varphi}^\top \, \dot{M}_\varphi(h^{-1}(\varphi)) \, \dot{\varphi} - \dot{\varphi}^\top \, \left ( \partial_{\varphi} \mathcal{U}_\varphi(\varphi) - \partial_{\varphi} \mathcal{U}_\varphi(\varphi^\mathrm{d}) \right ),\\
    =& \: -\dot{\varphi}^\top \, D_\varphi(h^{-1}(\varphi)) \, \dot{\varphi} - \dot{\varphi}_\mathrm{a}^\top \, K_\mathrm{d} \, \dot{\varphi}_\mathrm{a}, \succ 0 \quad \forall \: \varphi,\dot{\varphi} \in \mathbb{R}^{m}, K_\mathrm{d} \succeq 0,
\end{split}
\end{equation}

As previously mentioned, the statically attainable equilibrium $(\varphi^\mathrm{d},0_n)$ is locally asymptotically stable for sufficiently large proportional gains $K_\mathrm{p}$.
If the robot is elastically dominated with
\begin{equation}\footnotesize
    \frac{\partial^2 \mathcal{U}_\varphi(\varphi)}{\partial \varphi_\mathrm{u}^2} = \frac{\partial}{\partial \varphi_\mathrm{u}} \left ( -A_\mathrm{u}(h^{-1}(\varphi)) \, A_\mathrm{a}^{-1}(h^{-1}(\varphi)) \left ( G_\mathrm{a}(h^{-1}(\varphi)) + K_\mathrm{a}(h^{-1}(\varphi)) \right ) + G_\mathrm{u}(h^{-1}(\varphi)) + K_\mathrm{u}(h^{-1}(\varphi)) \right ) \succ 0 \quad \forall \: \varphi \in \mathbb{R}^n,
\end{equation}
the regulator additionally achieves \gls{GAS} for a sufficiently large $K_\mathrm{p} \succ 0$~\citep{pustina2025analysis}.

\subsubsection{Setpoint Regulation with Gravity Cancellation and Compensation of Elastic Forces for Elastically Decoupled Soft Robots}
Elastically decoupled soft robots are defined as the generalized elastic force taking the form~\citep{pustina2025analysis}
\begin{equation}
    \frac{\partial \mathcal{U}_{\varphi,\mathrm{K}}}{\partial \varphi}(\varphi) = \begin{bmatrix}
        \frac{\partial \mathcal{U}_{\varphi,\mathrm{K}}}{\partial \varphi_\mathrm{a}}(\varphi_\mathrm{a})\\
        \frac{\partial \mathcal{U}_{\varphi,\mathrm{K}}}{\partial \varphi_\mathrm{u}}(\varphi_\mathrm{u})
    \end{bmatrix} = \begin{bmatrix}
        A_\mathrm{a}^{-1}(h^{-1}(\varphi_\mathrm{a})) K_\mathrm{a}(h^{-1}(\varphi_\mathrm{a}))\\
        -A_\mathrm{u}(h^{-1}(\varphi_\mathrm{u})) \, A_\mathrm{a}^{-1}(h^{-1}(\varphi_\mathrm{u})) K_\mathrm{a}(h^{-1}(\varphi_\mathrm{u})) + K_\mathrm{u}(h^{-1}(\varphi_\mathrm{u}))
    \end{bmatrix},
\end{equation}
which is for example the case for $A(q) = A$ and linear elasticity $K(q) = S \, q$, where $S \in \mathbb{R}^{n\times n}$ is defined in a decoupled form
\begin{equation}
    S = \begin{bmatrix}
        S_\mathrm{aa} & 0_{m \times (n-m)}\\
        0_{(n-m) \times m} & S_\mathrm{uu}
    \end{bmatrix}.
\end{equation}

In this case, a regulator that cancels the gravitational forces and compensates the elastic forces on the actuated coordinates
\begin{equation}
    \tau_\mathrm{mb}(\varphi) = \underbrace{\frac{\partial \mathcal{U}_{\varphi,\mathrm{G}}(\varphi)}{\partial \varphi_\mathrm{a}}}_\text{Cancel Gravity} + \underbrace{\frac{\partial \mathcal{U}_{\varphi,\mathrm{K}}(\varphi)}{\partial \varphi_\mathrm{a}} \bigg |_{\varphi_\mathrm{a}=\varphi_\mathrm{a}^\mathrm{d}}}_\text{Compensate Elasticity} = \underbrace{A_\mathrm{a}^{-1}(q) \, G_\mathrm{a}(h^{-1}(\varphi))}_\text{Cancel Gravity} + \underbrace{A_\mathrm{a}^{-1}(h^{-1}(\varphi_\mathrm{a})) \, K_\mathrm{a}(h^{-1}(\varphi_\mathrm{a}))}_\text{Compensate Elasticity},
\end{equation}
renders the $\varphi_\mathrm{a} = \varphi_\mathrm{a}^\mathrm{d}$ to be globally asymptotically stable provided sufficiently large proportional feedback gains $K_\mathrm{p} \succeq 0$~\citep{pustina2025analysis}.
This system exhibits the closed-loop dynamics
\begin{equation}\footnotesize
    \begin{bmatrix}
        M_{\varphi,\mathrm{aa}}(q) & M_{\varphi,\mathrm{au}}(q)\\ 
        M_{\varphi,\mathrm{ua}}(q) & M_{\varphi,\mathrm{uu}}(q)
    \end{bmatrix} \, \ddot{\varphi} + \begin{bmatrix}
        \eta_{\varphi,\mathrm{a}}(q,\dot{q})\\ \eta_{\varphi,\mathrm{u}}(q,\dot{q})
    \end{bmatrix} \, \dot{\varphi} + \begin{bmatrix}
       \partial_{\varphi_\mathrm{a}} \mathcal{U}_{\varphi,\mathrm{K}}(\varphi) - \partial_{\varphi_\mathrm{a}} \mathcal{U}_{\varphi,\mathrm{K}}(\varphi^\mathrm{d}) + K_\mathrm{p} \left ( \varphi_\mathrm{a} - \varphi^\mathrm{d}_\mathrm{a} \right ) + K_\mathrm{d} \, \dot{\varphi}_\mathrm{a}\\
       \partial_{\varphi_\mathrm{u}} \mathcal{U}_{\varphi,\mathrm{G}}(\varphi) + \partial_{\varphi_\mathrm{u}} \mathcal{U}_{\varphi,\mathrm{K}}(\varphi)
    \end{bmatrix} + \begin{bmatrix}
        D_{\varphi,\mathrm{a}}(q)\\
        D_{\varphi,\mathrm{u}}(q)
    \end{bmatrix} \, \dot{\varphi} = \begin{bmatrix}
        0_m\\ 0_{n-m}
    \end{bmatrix}.
\end{equation}
We can use the Lyapunov candidate
\begin{equation}
\begin{split}\small
    V(\varphi, \dot{\varphi}) =& \: \underbrace{\frac{1}{2} \, \dot{\varphi}^\top \, M_\varphi(h^{-1}(\varphi)) \, \dot{\varphi}}_\text{Kinetic Energy} + \underbrace{\mathcal{U}_{\varphi,\mathrm{G}}(\varphi) - \mathcal{U}_{\varphi,\mathrm{G}_\mathrm{a}}(\varphi) - \mathcal{U}_{\varphi,\mathrm{G}_\mathrm{u}}(\varphi^\mathrm{d})}_\text{Centered Gravitational Potential Energy} + \underbrace{\mathcal{U}_{\varphi,\mathrm{K}}(\varphi) - \mathcal{U}_{\varphi,\mathrm{K}}(\varphi^\mathrm{d})}_\text{Centered Elastic Potential Energy}\\
    & \: + \underbrace{\frac{\partial \mathcal{U}_\varphi(\varphi)}{\partial \varphi_\mathrm{a}} \Bigg |_{\varphi = \varphi^\mathrm{d}}^\top \left ( \varphi_\mathrm{a}^\mathrm{d} - \varphi_\mathrm{a} \right )}_\text{Correction Term on Actuated Coord.} + \underbrace{\frac{1}{2} \, (\varphi_\mathrm{a}-\varphi_\mathrm{a}^\mathrm{d})^\top \, K_\mathrm{p} \, (\varphi_\mathrm{a}-\varphi_\mathrm{a}^\mathrm{d})}_\text{Artificial Potential Energy},
\end{split}
\end{equation}
where
\begin{equation}
\begin{split}
    \mathcal{U}_{\varphi,\mathrm{G}}(\varphi) = \mathcal{U}_{\varphi,\mathrm{G}_\mathrm{a}}(\varphi) + \mathcal{U}_{\varphi,\mathrm{G}_\mathrm{u}}(\varphi),
\end{split}
\end{equation}
with $\mathcal{U}_{\varphi,\mathrm{G}_\mathrm{a}}(\varphi)$ and $\mathcal{U}_{\varphi,\mathrm{G}_\mathrm{u}}(\varphi)$ the gravitational potential energy of the actuated and unactuated coordinates, respectively.
These quantities can be computed as
\begin{equation}
\begin{split}
    \mathcal{U}_{\varphi,\mathrm{G}_\mathrm{a}}(\varphi) =& \: \int A_\mathrm{a}^{-1}(q) \, G_\mathrm{a}(h^{-1}(\varphi)) \, \mathrm{d}\varphi_\mathrm{a},\\
    \mathcal{U}_{\varphi,\mathrm{G}_\mathrm{u}}(\varphi) =& \: \int -A_\mathrm{u}(h^{-1}(\varphi)) \, A_\mathrm{a}^{-1}(h^{-1}(\varphi)) \, G_\mathrm{a}(h^{-1}(\varphi)) + G_\mathrm{u}(h^{-1}(\varphi)) \, \mathrm{d}\varphi_\mathrm{u},\\
\end{split}
\end{equation}
and need to fulfill the properties
\begin{equation}
    \frac{\partial \mathcal{U}_{\varphi,\mathrm{G}_\mathrm{a}}(\varphi)}{\partial \varphi_\mathrm{a}} = \frac{\partial \mathcal{U}_{\varphi,\mathrm{G}}(\varphi)}{\partial \varphi_\mathrm{a}},
    \qquad
    \frac{\partial \mathcal{U}_{\varphi,\mathrm{G}_\mathrm{u}}(\varphi)}{\partial \varphi_\mathrm{u}} = \frac{\partial \mathcal{U}_{\varphi,\mathrm{G}}(\varphi)}{\partial \varphi_\mathrm{u}}.
\end{equation}
This Lyapunov function has the associated time derivative
\begin{equation}
    \dot{V}(\varphi,\dot{\varphi}) = -\dot{\varphi}^\top \, D_\varphi(h^{-1}(\varphi)) \, \dot{\varphi} - \dot{\varphi}_\mathrm{a}^\top \, K_\mathrm{d} \, \dot{\varphi}_\mathrm{a}, \succ 0 \quad \forall \: \varphi,\dot{\varphi} \in \mathbb{R}^{m}, K_\mathrm{d} \succeq 0,
\end{equation}
to analyze the stability properties in more detail.

\subsection{Integrated Controllers}\label{sub:background:model_based_control:integrated_controllers}
In the following, we will discuss some common closed-form model-based controllers that cannot (easily) be separated into a model-based term and an error-based feedback term.
For simplicity, we assume in the following the fully actuated case - i.e., $n=m$, $\varphi = \varphi_\mathrm{a}$, $M_{\varphi}(q) = M_{\varphi,\mathrm{a}}(q)$, etc.

\subsubsection{P-satI-D+Potential Shaping}
The \emph{P-satI-D+Potential Shaping} controller consists of \emph{P-satI-D} feedback term and the \emph{Setpoint Regulation with Feedforward Compensation} model-based term.
As we frequently use this controller throughout this thesis, such as in Chapter~\ref{chp:hsacontrol} (underactuated version), and Chapter~\ref{chp:pcsregression} \& \ref{chp:con}, we will below specify the control law, assuming a constant actuation matrix $A(q) = A$
\begin{equation}
\begin{split}
    \tau(t,q,\dot{q}) =& \: \underbrace{A^{-1} \, \left ( G(q^\mathrm{d}) + K(q^\mathrm{d}) \right )}_\text{Model-Based Feedforward}\\
    & \: + \underbrace{K_\mathrm{p} \left (\varphi^\mathrm{d}(t) - \varphi(t) \right ) + K_\mathrm{i} \int_0^t \tanh \left ( \gamma \, ( \varphi^\mathrm{d}(t')-\varphi(t') ) \right ) \: \mathrm{d} t' + K_\mathrm{d} \left ( \dot{\varphi}^\mathrm{d}(t) - \dot{\varphi}(t) \right )}_\text{Model-Free Feedback Term: P-satI-D},
\end{split}
\end{equation}
which generates the closed-loop dynamics
\begin{equation}
\begin{split}
    M_\varphi(q) \, \ddot{\varphi} + \eta_\varphi(q,\dot{q}) \, \dot{\varphi} + A^{-1} \left ( G(q) + K(q) - G(q^\mathrm{d}) - K(q^\mathrm{d}) \right ) + D_\varphi \, \dot{\varphi}\\
    + K_\mathrm{p} \left (\varphi(t) - \varphi^\mathrm{d}(t) \right ) + K_\mathrm{d} \left ( \dot{\varphi}(t) - \dot{\varphi}^\mathrm{d}(t) \right ) + K_\mathrm{i} \int_0^t \tanh \left ( \gamma \, ( \varphi(t')-\varphi^\mathrm{d}(t') ) \right ) \: \mathrm{d} t' = 0_n,
\end{split}
\end{equation}
where $K_\mathrm{p}, K_\mathrm{i}, K_\mathrm{d} \succeq 0 \in \mathbb{R}^{n \times n}$ are the proportional, integral, and derivative feedback gains, respectively.

% In case of linear elasticity $K(q) = S \, q$, the closed loop dynamics simplify to 

\subsubsection{Feedback Linearization via Computed Torque}
The idea behind (full) feedback linearization~\citep{slotine1987on, spong2020robot} is to 
cancel the existing dynamics of the robot and ensure that the closed-loop system exhibits linear dynamics - usually established via a PD term. A computed torque controller for soft robots assumes the form
\begin{equation}\small
    \tau(t,q,\dot{q}) = M_{\varphi}(q) \, \left (K_\mathrm{p} \left (\varphi^\mathrm{d} - \varphi \right ) + K_\mathrm{d} \left (\dot{\varphi}^\mathrm{d} - \dot{\varphi} \right ) + \ddot{\varphi}^\mathrm{d}\right ) + \left ( \eta_{\varphi}(q,\dot{q}) + D_\varphi(q) \right ) \, \dot{\varphi} + A^{-1}(q) \left ( G(q) + K(q) \right ),
\end{equation}
where $K_\mathrm{p}, K_\mathrm{d} \in \mathbb{R}^{n \times n}$ are proportional and derivative control gains for tracking the desired actuation coordinate and actuation velocity, respectively. 
The closed-loop dynamics read as
\begin{equation}\label{eq:background:model_based_control:feedback_linearization:closed_loop_dynamics}
    M_{\varphi}(q) \left (K_\mathrm{p} \left (\varphi - \varphi^\mathrm{d} \right ) + K_\mathrm{d} \left (\dot{\varphi} - \dot{\varphi}^\mathrm{d} \right ) + \left ( \ddot{\varphi} - \ddot{\varphi}^\mathrm{d} \right ) \right ) = 0.
\end{equation}
After defining the control error as $e(t) = \varphi(t) - \varphi^\mathrm{d}(t)$ with $\dot{e}(t) = \dot{\varphi}(t) - \dot{\varphi}^\mathrm{d}(t)$ and $\ddot{e}(t) = \ddot{\varphi}(t) - \ddot{\varphi}^\mathrm{d}(t)$, the dynamics of Eq.~\ref{eq:background:model_based_control:feedback_linearization:closed_loop_dynamics} can be rewritten as
\begin{equation}
    \ddot{e}(t) + K_\mathrm{d} \, \dot{e}(t) + K_\mathrm{p} \, e(t) = 0,
\end{equation}
which lets us notice that now linear dynamics govern with stiffness $K_\mathrm{p}$ and damping factor $K_\mathrm{d}$ govern the closed-loop system behavior.
If we assume scalar control gains $K_\mathrm{p}, K_\mathrm{d} \in \mathbb{R}_+$, these error dynamics converge exponentially fast to the global equilibrium $e(t) = 0$ with decay time $\frac{1}{K_\mathrm{d}}$. Specifically, we can always choose the control such that the closed-loop system exhibits a critically damped behavior $\frac{K_\mathrm{d}}{2} = \sqrt{K_\mathrm{p}}$.
The evolution of the error is then given in closed form as
\begin{equation}\label{eq:background:model_based_control:feedback_linearization:error_evolution_closed_form}
    e(t) = \left ( e_0 + \left ( \dot{e}_0 + \frac{K_\mathrm{d}}{2} \, e_0 \right ) (t-t_0) \right ) \, e^{-\frac{K_\mathrm{d}}{2} (t - t_0)},
\end{equation}
where $e_0, \dot{e}_0$ are the initial error and its velocity at $t_0$.

As seen in this derivation, computed torque controllers exhibit very nice stability and convergence properties. However, this comes at the cost of requiring high control rates, precise actuator motion, high control effort, and, most importantly, very accurate modeling of the system dynamics. In case of modeling errors, the stability characteristics can be lost, and the unmodelled dynamics can quickly become dominant.
So far, computed torque controllers have been verified for fully actuated soft robots in simulation~\citep{boyer2006macro, pustina2024unified}, but to the best of our knowledge, not yet experimentally.


\subsubsection{Operational Space Impedance Control}
% A operational space impedance controller leverages the partial feedback linearization framework to cancel out the existing task dynamics and establish new linear dynamics with stiffness matrix $K_\mathrm{x} \in \mathbb{R}^{o \times o}$ and damping matrix $D_\mathrm{x} \in \mathbb{R}^{o \times o}$ that regulates the closed-loop system towards the operational space reference $x^\mathrm{d} \in \mathbb{R}^o$~\citep{khatib1987unified, della2020model}
An operational space impedance controller uses partial feedback linearization to cancel out the original task dynamics and replace them with a new set of linear dynamics in operational space $x \in \mathbb{R}^n$. These new dynamics are defined by a stiffness matrix $K_\mathrm{x} \in \mathbb{R}^{o \times o}$ and a damping matrix $D_\mathrm{x} \in \mathbb{R}^{o \times o}$, which together drive the closed-loop system toward the desired operational space reference $x^\mathrm{d} \in \mathbb{R}^o$~\citep{khatib1987unified, della2020model}.
\begin{equation}\small
\begin{split}
    \tau =& \: \underbrace{A^{-1}(q)}_{J_\mathrm{h}^{-\top}(q)} \, \big ( \underbrace{J^\top(q) \, J_\mathrm{M}^{+\top}(q) \left ( K(q) + D \, \dot{q} \right )}_\text{Cancel Elastic \& Diss. Forc. Acting on Task} + \underbrace{G(q)}_\text{Cancel Gravity} \big )\\
    + & \: A^{-1}(q) \, \big ( \underbrace{J^\top(q) \, \eta_\mathrm{x}(q,\dot{q}) \left ( \mathbb{I}_n - J_\mathrm{M}^{+}(q) \, J(q)  \right ) \, \dot{q}}_\text{Cancel Coupling of Null-Space Coriolis Force on Task} + \underbrace{J^\top(q) \left ( K_\mathrm{x} \, (x^\mathrm{d} - x) - D_\mathrm{x} \, \dot{x} \right )}_{\text{PD for Shaping Operational Space Impedance}} \big ).
\end{split}
\end{equation}
% As previously already mentioned, this impedance controller assumes (a) full actuation (i.e., $n=m$), (b) that $A(q) \in \mathbb{R}{n \times n}$ is invertible~\citep{della2020model}, (c) the dimensionality of the operational space with coordinates $x \in \mathrm{R}^\mathrm{o}$ is smaller than the of the configuration space (i.e., $m \leq n$), and (d) that the null-space is asymptotically stable which should generally be the case if $K(q) = S \, q$ with $S \succ 0$ and $D \succ 0$.
As noted earlier, the impedance controller relies on several key assumptions. It presumes (a) full actuation (i.e., $n = m$), (b) that the matrix $A(q) \in \mathbb{R}^{n \times n}$ is invertible~\citep{della2020model}, (c) that the operational space—characterized by coordinates $x \in \mathbb{R}^{o}$—has lower dimensionality than the configuration space (i.e., $m \leq n$), and (d) that the null space is asymptotically stable, a condition typically met when $K(q) = S \, q$ with $S \succ 0$ and $D \succ 0$.

In the following, we will guide the reader step-by-step through the control design.
First, we cancel the gravitational forces of the system via $\tau_\mathrm{q} = G(q)$. Please note that this immediately ensures that gravity is not acting anymore on the closed-loop null-space dynamics, which could potentially cause instability.
Now, the updated operational and null space dynamics are given by
\begin{equation}
    \begin{bmatrix}
        \Lambda_\mathrm{x}(q) & 0_{o \times (n-o)}\\
        0_{(n-o) \times o} & \Lambda_\mathrm{n}(q)
    \end{bmatrix} \, \begin{bmatrix}
        \ddot{x}\\
        \dot{\nu}_\mathrm{n}
    \end{bmatrix} + \begin{bmatrix}
        \eta_\mathrm{xx}(q,\dot{q}) & \eta_\mathrm{xn}(q,\dot{q})\\
        \eta_\mathrm{nx}(q,\dot{q}) & \eta_\mathrm{nn}(q,\dot{q})
    \end{bmatrix} \, \begin{bmatrix}
        \dot{x}\\ \nu_\mathrm{n}
    \end{bmatrix} + \begin{bmatrix}
        J_\mathrm{B}^{+\top}(q)\\
        Z(q)
    \end{bmatrix} \, \left ( K(q) + D \, \dot{q} \right ) = \begin{bmatrix}
        f_\mathrm{x}\\ f_\mathrm{n}
    \end{bmatrix}.
\end{equation}
Next, we devise an operational space force $f_\mathrm{x} \in \mathbb{R}^o$
\begin{equation}
    f_\mathrm{x} = \underbrace{J_\mathrm{M}^{+\top}(q) \left ( K(q) + D \, \dot{q} \right )}_{f_\mathrm{KD}}
    + \underbrace{\eta_\mathrm{x}(q,\dot{q}) \left ( \mathbb{I}_n - J_\mathrm{M}^{+}(q) \, J(q)  \right ) \, \dot{q}}_{f_{\eta_\mathrm{xn}}}
    + \underbrace{K_\mathrm{x} \, (x^\mathrm{d} - x) - D_\mathrm{x} \, \dot{x}}_{f_\mathrm{PD}},
\end{equation}
% that cancels the existing operational space dynamics, removes the remaining coupling from the null space dynamics, and creates new linear dynamics with a tunable impedance and an asymptotically stable equilibrium at $x^\mathrm{d}$ via a PD term. 
% Diving into more detail, the force $f_\mathrm{KD}$ cancels the existing operational space elastic and dissipative forces.
% Next, the purpose of the term $f_{\eta_\mathrm{xn}}$ is to remove the remaining coupling of the null space dynamics on the operational space dynamics from the closed loop system. Specifically, the aim is to eliminate the Coriolis forces of the null space acting on the operational space $\eta_\mathrm{xn}(q,\dot{q}) \, \nu_\mathrm{n}$. However, we want to avoid having to compute the null space online. We can avoid the derivation of the null space by performing the substitution~\citep{ott2008cartesian, della2020model}
that cancels the existing operational space dynamics, decouples the remaining null space interactions, and establishes new linear dynamics with a tunable impedance and an asymptotically stable equilibrium at $x^\mathrm{d}$ via a PD term. In more detail, the force $f_\mathrm{KD}$ eliminates the inherent elastic and dissipative forces in the operational space. Next, the term $f_{\eta_\mathrm{xn}}$ is designed to remove any residual coupling from the null space dynamics on the operational space, specifically by canceling the null space Coriolis forces $\eta_\mathrm{xn}(q,\dot{q}) \, \nu_\mathrm{n}$. To avoid computing the null space online, we bypass its derivation by performing the substitution outlined in~\citep{ott2008cartesian, della2020model}.
\begin{equation}
\begin{split}
    f_{\eta_\mathrm{xn}} =& \: \eta_\mathrm{xn}(q,\dot{q}) \, \nu_\mathrm{n} = \eta_\mathrm{x}(q,\dot{q}) \, \dot{q} - \eta_\mathrm{xx}(q,\dot{q}) \, \dot{q},\\
    =& \: \eta_\mathrm{x}(q,\dot{q}) \, \dot{q} - \eta_\mathrm{x}(q,\dot{q}) \, J_\mathrm{M}^+(q) \, \dot{x} = \eta_\mathrm{x}(q,\dot{q}) \, \dot{q} - \eta_\mathrm{x}(q,\dot{q}) \, J_\mathrm{M}^+(q) \, J(q) \, \dot{q}\\
    =& \: \eta_\mathrm{x}(q,\dot{q}) \left ( \mathbb{I}_n - J_\mathrm{M}^{+}(q) \, J(q)  \right ) \, \dot{q},
\end{split}
\end{equation}
as $\dot{x} = J(q) \, \dot{q}$ and $\eta_\mathrm{xx}(q,\dot{q}) = \eta_\mathrm{x}(q,\dot{q}) \, J_\mathrm{M}^+(q)$.
The removal of the existing operational space dynamics allows us then to establish the desired impedance. Specifically, PD term $f_\mathrm{PD}$ creates an artificial potential field $\mathcal{U}_\mathrm{x}(x) = \frac{1}{2}x^\top \, K_\mathrm{x} \, x$ and establishes dissipation which ensures asymptotic stability of the operational space dynamics.
This forcing $f_\mathrm{x}$ results in the closed-loop task and null space dynamics
\begin{equation}
    \begin{bmatrix}
        \Lambda_\mathrm{x}(q) & 0_{o \times (n-o)}\\
        0_{(n-o) \times o} & \Lambda_\mathrm{n}(q)
    \end{bmatrix} \, \begin{bmatrix}
        \ddot{x}\\
        \dot{\nu}_\mathrm{n}
    \end{bmatrix} + \begin{bmatrix}
        \eta_\mathrm{xx}(q,\dot{q}) & 0_{o \times (n-o)}\\
        \eta_\mathrm{nx}(q,\dot{q}) & \eta_\mathrm{nn}(q,\dot{q})
    \end{bmatrix} \, \begin{bmatrix}
        \dot{x}\\ \nu_\mathrm{n}
    \end{bmatrix} + \begin{bmatrix}
        K_\mathrm{x} \, (x - x^\mathrm{d}) - D_\mathrm{x} \, \dot{x}\\
        Z(q) \left ( K(q) + D \, \dot{q} \right )
    \end{bmatrix} = 0_{n}.
\end{equation}
We can extract several interesting observations by analyzing these closed-loop dynamics in more detail. First, the operational space dynamics
\begin{equation}
    \Lambda_\mathrm{x}(q) \, \ddot{x} + K_\mathrm{x} \, (x - x^\mathrm{d}) - D_\mathrm{x} \, \dot{x} = 0_{o},
\end{equation}
now mirror the ones of coupled damped harmonic oscillators.
% Furthermore, we can easily prove, analog to the computed torque controller, that they converge exponentially fast to the global asymptotic equilibrium $x^\mathrm{d}$.
% In the spirit of the previously introduced setpoint regulation controllers with gravity cancellation and compensation of elastic forces, we don't fully eliminate the null space dynamics but instead increase robustness against disturbances and modeling errors by preserving the natural elasticity and dissipation of the system while only removing the gravitational forces. This results in closed-loop null-space dynamics that converge in steady-state to the minimum of the operational space potential field.
Furthermore, similar to the computed torque controller, we can readily demonstrate that they converge exponentially fast to the global asymptotic equilibrium $x^\mathrm{d}$. In line with the previously introduced setpoint regulation controllers that cancel gravitational forces while compensating for elastic forces, we do not entirely eliminate the null space dynamics. Instead, we enhance robustness against disturbances and modeling errors by preserving the system’s natural elasticity and dissipation while only removing the gravitational forces. This approach yields closed-loop null-space dynamics that settle in steady-state at the (local) minimum of their potential field.

% After designing the desired forces in operational space $f_\mathrm{x}$, we can easily derive the control input via configuration space. First, $f_\mathrm{x}$ is projected into configuration space, resulting in a sum between the projected operational space forces and the gravity cancellation: $\tau_\mathrm{q} = J^\top(q) \, f + G(q)$ 
% Finally, the inverse of the actuation matrix can be used to devise the control input based on the desired configuration space torques $\tau = A^{-1}(q) \, \tau_\mathrm{q}$.
After designing the desired forces in operational space $f_\mathrm{x}$, the control input can be derived via a projection into configuration space. First, $f_\mathrm{x}$ is mapped into configuration space, resulting in a combination of the projected operational space forces and gravity cancellation: $\tau_\mathrm{q} = J^\top(q) \, f + G(q)$. Finally, by applying the inverse of the actuation matrix, the control input based on the desired configuration space torques is obtained as $\tau = A^{-1}(q) \, \tau_\mathrm{q}$.

% We propose a variation of this operational space impedance controller that is specialized to Cartesian control of underactuated planar \gls{HSA} robots in Chapter~\ref{chp:hsacontrol}.
We propose a variation of this operational space impedance controller tailored to the Cartesian control of underactuated planar \gls{HSA} robots in Chapter~\ref{chp:hsacontrol}.
\section{Motivation}\label{sec:introduction:motivation}
% \dropcap{T}his is a introductory page.

% The last decades have shown great progress in robotics, with performant, precise, and powerful rigid robots now being widely adopted~\cite{todd1996fundamentals}, particularly in manufacturing scenarios where repetitive movements are prevalent within assembly line manufacturing, but more and more also in domains that require a larger degree of autonomy, such as warehouse logistics, automated inspections, etc.
% However, to address pressing societal challenges, there is a growing demand for robotic systems that are specifically designed for and adaptable to human-centered environments (e.g., homes and public spaces)~\cite{nahavandi2019industry, chibani2013ubiquitous, royakkers2015literature, he2021challenges}.
% To unlock their full potential, robots must be designed with inherent physical compliance to operate safely around humans in dynamic, unconstrained, unpredictable settings.
% Such requirement aligns with Asimov's First Law--robots must never harm humans--making safety fundamental to their design and deployment~\cite{villani2018survey}.
Over the past few decades, the domain of robotics has made remarkable strides, leading to the widespread adoption of high-performance, precise, and powerful rigid robots~\cite{todd1996fundamentals}. While these systems have traditionally excelled in manufacturing environments with repetitive tasks—such as assembly lines—they are increasingly finding use in applications that require more autonomy, including warehouse logistics and automated inspections. Yet, in addressing contemporary societal needs, there is a heightened demand for robots specifically crafted for human-centered settings (e.g., homes and public spaces)~\cite{nahavandi2019industry, chibani2013ubiquitous, royakkers2015literature, he2021challenges}. Fully realizing the potential of such robots calls for integrating inherent compliance, enabling safe interaction with humans in dynamic, unconstrained, and unpredictable contexts. This requirement aligns with Asimov’s First Law~\cite{asimov1941three}—robots must never harm humans—making safety a paramount consideration in both their design and deployment~\cite{villani2018survey}.

% While safety is traditionally ensured through computational control policies, this approach is vulnerable to perception errors and often results in overly cautious behavior that limits robot performance. Soft robotics presents a promising alternative by establishing passive compliance throughout the entire robot body with material softness. This embodied intelligence is inherently resistant to perception or control
% errors. Recent years have witnessed remarkable progress in
% soft robotics, with researchers developing new designs, smart
% materials, actuators, sensors, models, and control approaches.

% Existing strategies mostly try to ensure safety via computational intelligence; for example, they advanced control mechanisms such as safety filters or impedance controllers, real-time collision detection, and predefined safety zones~\cite{zhao2024potential}. 
% For this task, they rely on sophisticated sensors, algorithms, and extensive pre-programming to anticipate and avoid hazards \cite{fragapane2021planning}.
% For example, collision detection enhances safety by stopping or slowing the robot upon contact. While reducing the worst-case injury likelihood, this approach is inherently reactive and cannot fully prevent injuries.
% However, in case of sensor failure or errors in the perception and/or reasoning pipeline, safety cannot be guaranteed anymore.
% There has also been work to improve safety through hardware.
% For example, \gls{Cobot}~\cite{el2019cobot}, designed to safely interact with humans, often use series elastic actuators to decouple the actuator from the link dynamics~\cite{pratt1995series} and aim to reduce the link inertia~\cite{albu2007dlr}.
% Yet, their rigid body still poses significant risks to nearby humans~\cite{haddadin2013towards}.
% In order to reduce safety risks, design standards such as ISO/TS 15066:2016~\cite{Isots_15066_2016} demand that \gls{cobot} move slowly enough to stop in time to prevent collisions, limiting their effectiveness and performance~\cite{ajoudani2018progress, lucci2020combining}.
% In conclusion, the current strategies pose high requirements on perception systems and significantly reduce the robots/cobots' efficiency and effectiveness in the context of human-centered environments.
Existing approaches to ensuring safety largely depend on computational intelligence, employing advanced control strategies (e.g., safety filters~\cite{ames2016control} and impedance controllers~\cite{khatib1987unified}), real-time collision detection~\cite{haddadin2017robot}, and predefined safety zones~\cite{zhao2024potential}. These methods leverage sophisticated sensing, algorithms, and extensive pre-programming to predict and mitigate potential hazards~\cite{fragapane2021planning}. For instance, collision detection improves safety by stopping or slowing the robot upon contact. Although this measure helps reduce the risk of serious injury, it is inherently reactive and cannot entirely eliminate harm. Moreover, any sensor malfunction or failure in the perception or decision-making pipeline undermines safety guarantees.
Hardware-based solutions have also been developed to enhance safety. For example, \glspl{Cobot}~\cite{el2019cobot}, which are designed for safe human-robot interaction, typically incorporate series elastic actuators to isolate actuator dynamics from the robot’s links~\cite{pratt1995series} and minimize link inertia~\cite{albu2007dlr}. Still, their rigid structures pose considerable risks to nearby individuals~\cite{haddadin2013towards}. To address these dangers, standards such as ISO/TS 15066:2016~\cite{Isots_15066_2016} mandate that \glspl{Cobot} move slowly enough to stop before colliding with a person, thereby constraining performance and effectiveness~\cite{ajoudani2018progress, lucci2020combining}. Ultimately, current safety measures place heavy demands on perception systems and substantially reduce the efficiency and capabilities of robots and \glspl{Cobot} in human-centered environments.

% Interestingly, soft robotics redefines safety from the ground up. 
% In these robots~\cite{rus2015design, laschi2016soft}, safety is not an add-on or managed through computational stacks but is embedded in the material and structural properties of the robot itself. 
% Their compliant nature allows soft robots to interact safely with humans and operate in sensitive environments where safety is essential, such as personal assistance, caregiving, and handling delicate objects and produce~\cite{abidi2017intrinsic}. 
% Recent years have witnessed remarkable progress in soft robotics~\cite{yasa2023overview}, with researchers developing new designs~\cite{laschi2012soft, hawkes2017soft, guan2023trimmed, katzschmann2018exploration, tolley2014resilient}, smart materials~\cite{terryn2017self, mazzolai2022roadmap}, actuators~\cite{shepherd2013using, vasios2020harnessing, lipton2018handedness, gravert2024low, wehner2016integrated, aubin2022towards}, sensors~\cite{larson2016highly, thuruthel2019soft, truby2020distributed}, models~\cite{renda2018discrete, boyer2020dynamics, renda2020geometric}, and control~\cite{thuruthel2018model, della2020model, jitosho2023reinforcement, pustina2024input} approaches. 
% Despite their potential to revolutionize human-robot interaction~\cite{jorgensen2022soft}, soft robots face significant challenges hindering their full integration into practical applications~\cite{hawkes2021hard}. 
% Particularly, current soft robots often exhibit imprecise and often oscillatory motion~\cite{mazzolai2022roadmap, majidi2014soft, hawkes2017soft}.
% The reason is that modeling~\cite{armanini2023soft} and control~\cite{della2023model} of continuum soft robots presents significant challenges due to their infinite degrees of freedom, complex nonlinear dynamics, and time-dependent behaviors such as hysteresis.
Soft robotics reimagines safety from the ground up by embedding it into the robot’s fundamental mechanical design. Rather than treating safety as an add-on or relying solely on computational layers, soft robots incorporate safety through the choice of materials and structural configurations~\cite{rus2015design, laschi2016soft}. Their inherent compliance facilitates safe interactions with humans and makes them ideal for safety-critical settings like personal assistance, caregiving, and handling delicate items~\cite{abidi2017intrinsic, yumbla2021human}.
Recent advancements in the field have been substantial~\cite{yasa2023overview}, with innovations in soft robot designs~\cite{laschi2012soft, hawkes2017soft, guan2023trimmed, katzschmann2018exploration, tolley2014resilient}, smart materials~\cite{terryn2017self, mazzolai2022roadmap}, actuators~\cite{shepherd2013using, vasios2020harnessing, lipton2018handedness, gravert2024low, wehner2016integrated, aubin2022towards}, sensors~\cite{larson2016highly, thuruthel2019soft, truby2020distributed}, modeling methods~\cite{renda2018discrete, boyer2020dynamics, renda2020geometric}, and control techniques~\cite{thuruthel2018model, della2020model, jitosho2023reinforcement, pustina2024input}. Despite this progress and the potential to transform human-robot interaction~\cite{jorgensen2022soft}, widespread practical adoption of soft robots remains a challenge~\cite{hawkes2021hard}. In particular, many soft robots still struggle with imprecise, often oscillatory motion~\cite{mazzolai2022roadmap, majidi2014soft, hawkes2017soft}. This is largely because modeling~\cite{armanini2023soft} and controlling~\cite{della2023model} continuum soft robots is inherently difficult; they exhibit infinite degrees of freedom, complex nonlinear dynamics, and time-dependent phenomena such as hysteresis~\cite{armanini2023soft}.
Therefore, we see a pressing need for novel motor control strategies for soft robots that combine the inherent compliance and embodied intelligence of soft robots with the precise motion characteristic of rigid robotic manipulators.

% At the moment, we can identify three dominant approaches for controlling the complex behavior of soft robots~\cite{thuruthel2018control, della2023model}:
% (1) leveraging fully physics-based models~\cite{armanini2023soft} (e.g., strain models~\cite{alessi2024rod}) for control, often using nonlinear feedback (e.g., PD+~\cite{della2020model}) or feedback+feedforward (e.g., PD+energy-shaping~\cite{della2023model, caasenbrood2023control} control schemes, (2) learning a model and subsequently exploiting it for control, be it via optimal control (e.g., \gls{LQR}~\cite{bruder2020data, haggerty2023control}, \gls{MPC}~\cite{gillespie2018learning, thuruthel2017learning, alora2023robust, alora2023data}, gradient-descent-based optimization~\cite{bern2020soft}), or model-based \gls{RL}~\cite{thuruthel2018model, centurelli2022closed}, or (3) directly learning the controller via model-free \gls{RL}~\cite{morimoto2021model, jitosho2023reinforcement, alessi2024pushing} or \gls{ILC}~\cite{hofer2019iterative, pierallini2023provably}.
% However, all strategies exhibit significant deficiencies and shortcomings:
At present, three main approaches can be distinguished for controlling the complex behavior of soft robots~\cite{thuruthel2018control, della2023model}. The first (1) relies on fully physics-based models~\cite{armanini2023soft}, for example using strain models~\cite{alessi2024rod}, and typically involves nonlinear feedback (e.g., PD+~\cite{della2020model}) or feedback+feedforward (e.g., PD+energy-shaping~\cite{della2023model, caasenbrood2023control}) control schemes. The second (2) consists in learning a model and then exploiting it for control, whether through optimal control methods (e.g., \gls{LQR}~\cite{bruder2020data, haggerty2023control}, \gls{MPC}~\cite{gillespie2018learning, thuruthel2017learning, alora2023robust, alora2023data}, or gradient-descent-based optimization~\cite{bern2020soft, marques2024visuo}) or via model-based \gls{RL}~\cite{thuruthel2018model, centurelli2022closed}. The third (3) approach is to learn the controller directly through model-free \gls{RL}~\cite{morimoto2021model, jitosho2023reinforcement, alessi2024pushing} or \gls{ILC}~\cite{hofer2019iterative, pierallini2023provably}. However, each of these strategies exhibits significant drawbacks.

% (1) the derivation and design of fully physics-based models requires a lot of expert knowledge~\cite{stella2023science} and many simplifying assumptions, such as that the continuum soft robot's body is \emph{slender} (i.e., the backbone radius is much smaller than its length)~\cite{cosserat1909theorie} and can be approximated effectively by a low-dimensional kinematic parametrization~\cite{armanini2023soft}, backbone cross-sections preserve a constant area~\cite{gazzola2018forward}, the material is isotropic, exhibits Hookean behavior and does not display time-dependent characteristics such as hysteresis, etc. As a result, fully physics-based models do not sufficiently capture the complex behavior of advanced soft robots, which in turn leads to unsatisfactory of control performance.
% Approach (2) - learning linear dynamical models, for example, following a Koopman approach~\cite{bruder2020data, bruder2024koopman} such that they can be controlled via \gls{LQR} is often unstable, exhibits an inherent trade-off between dimensionality and expressiveness, and cannot accurately capture the behavior of non-linearizable systems~\cite{cenedese2022data}. On the other hand, learning the dynamics using nonlinear functions, and in particular \glspl{DNN}, for example, with \glspl{MLP}, \glspl{RNN}~\cite{thuruthel2018model, sun2022physics}, \glspl{LSTM}~\cite{xie2023dynamic}, or \glspl{NODE}~\cite{kasaei2023data} is a more expressive approach, but control becomes computationally very expensive techniques such as \gls{MPC} or model-based \gls{RL} need to be used. Furthermore, we usually lack a physical interpretation of the learned model, preventing us from analyzing the stability of the open-loop or closed-loop system using standard techniques, such as Lyapunov arguments~\cite{khalil2002nonlinear}.
% The third existing approach, (3), in the case of \gls{RL} sample inefficient and lacks stability guarantees, and in the case of \gls{ILC} can only learn repetitive trajectories~\cite{bristow2006survey}.
% In particular, the sample inefficiency is a huge issue for soft robots as they exhibit changing material properties rendering previously learned controllers to be suboptimal, and a currently a limited lifetime~\cite{yasa2023overview} - which might mean that the soft robot might be damaged or broken before the (\gls{RL}) controller is fully trained.
Developing fully physics-based models, as used in (1), demands substantial expert knowledge~\cite{stella2023science} and often hinges on strong simplifying assumptions, such as the continuum soft robot being slender (i.e., the backbone radius is much smaller relative to its length)~\cite{cosserat1909theorie}, allowing for a low-dimensional kinematic parametrization~\cite{armanini2023soft}, preserving a constant backbone cross-section~\cite{gazzola2018forward}, and assuming isotropic Hookean materials without time-dependent effects like hysteresis. These assumptions fail to capture the intricate physics of many soft robots, undermining control performance. In approach (2), learning linear dynamical models—such as those based on a Koopman approach~\cite{bruder2020data, bruder2024koopman} often proves unstable, suffers from the trade-off between model dimensionality and expressiveness, and cannot accurately represent non-linearizable systems~\cite{cenedese2022data}. On the other hand, using nonlinear functions (notably \glspl{DNN}, including \glspl{MLP}, \glspl{RNN}~\cite{thuruthel2018model, sun2022physics}, \glspl{LSTM}~\cite{xie2023dynamic}, or \glspl{NODE}~\cite{kasaei2023data}) provides more expressive models but requires computationally heavy control techniques such as \gls{MPC} or model-based \gls{RL}, and typically lacks a clear physical interpretation that would permit stability analyses of both the open-loop and closed-loop system by conventional means (e.g., Lyapunov arguments~\cite{khalil2002nonlinear}). Discussing approach (3): Model-free \gls{RL}, meanwhile, tends to be sample inefficient and does not guarantee stability, whereas \gls{ILC} can only be used for learning repetitive trajectories~\cite{bristow2006survey}. The sample inefficiency is particularly problematic for soft robots since their material properties change over time—rendering previously learned controllers less effective—and their limited lifespans~\cite{yasa2023overview} risk the robot being damaged or failing altogether before a controller learned through \gls{RL} is fully trained.

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{introduction/figures/model_based_control_with_learned_models_v1_cropped.pdf}
    \caption{Model-based control of soft robots with learned models that exhibit a physical structure.}
    \label{fig:introduction:model_based_control_with_learned_models}
\end{figure}

% In this thesis, we aim to avoid all these deficiencies by combining learned models with closed-form control (see Fig.~\ref{fig:introduction:model_based_control_with_learned_models}).
% By integrating learned models into established feedback+feedforward control strategies, we combine the best of both worlds: learning models require less expert knowledge and allow us to capture mode complex dynamical effects while the closed-form feedback+feedforward controller is computationally extremely efficient.
% However, in order to apply feedback+feedforward control strategies, such as PD+energy-shaping~\cite{della2023model, caasenbrood2023control}, we need to be able to inspect the kinetic and potential energies of the learned model, which is generally not possible for existing popular \gls{ML} architectures such as \glspl{RNN}, \glspl{MLP}, or \glspl{NODE}.
% Therefore, we notice that the learned models need to exhibit a physical structure in order for us to be able to apply common model-based control schemes, such as PD+ or PD+feedforward, and to guarantee the stability of the closed-loop system using Lyapunov arguments.
As visualized in Fig.~\ref{fig:introduction:model_based_control_with_learned_models}, in this thesis, we seek to circumvent the aforementioned shortcomings by integrating learned models with closed-form control. By embedding learned models within established feedback+feedforward strategies, we benefit from both paradigms: learned models demand less specialized expertise while capturing more complex dynamical behaviors, and the closed-form feedback+feedforward controller remains computationally very efficient. However, to apply feedback+feedforward control approaches such as PD+energy-shaping~\cite{della2023model, caasenbrood2023control}, it is necessary to inspect the kinetic and potential energies of the learned model—something that existing popular \gls{ML} architectures like \glspl{RNN}, \glspl{MLP}, or \glspl{NODE} generally do not allow. Consequently, it becomes clear that the learned models must exhibit a physical structure in order to employ common model-based control schemes, such as PD+ or PD+energy shaping, and to secure closed-loop stability via Lyapunov arguments.

% In recent years, there has been an exciting development in this area with the nascent literature on \glspl{LNN}~\cite{lutter2019deep, cranmer2020lagrangian, liu2024physics} and \glspl{HNN}~\cite{greydanus2019hamiltonian, liu2024physics} which both explicitly learn the kinetic and potential energy of the system. However, they also exhibit significant drawbacks: the derivation of the \gls{EOM} requires the online computation of higher-order derivatives, which is computationally expensive (particularly during training but also during inference) and increases (GPU) memory requirements~\cite{lutter2019deep}. Furthermore, in a naive implementation, they do not exhibit any formal stability guarantees, and the computation of higher-order derivatives can introduce numerical stiffness or instability if not carefully managed (e.g., needing high-precision auto differentiation~\cite{rumelhart1986learning} or careful hyperparameter tuning). Finally, we identify a need for learning models that incorporate inductive biases on the specific dynamics exhibited by soft robots.
Recent advances in this direction include the emerging literature on \glspl{LNN}~\cite{lutter2019deep, cranmer2020lagrangian, liu2024physics} and \glspl{HNN}~\cite{greydanus2019hamiltonian, liu2024physics}, both of which explicitly learn the system’s kinetic and potential energies. Nevertheless, these approaches still present substantial challenges: deriving the \gls{EOM} necessitates real-time higher-order derivatives, which is computationally demanding—particularly during training, but also at inference—and escalates (GPU) memory usage~\cite{lutter2019deep}. Moreover, without careful implementation, they do not offer formal stability guarantees, and the computation of higher-order derivatives can cause numerical stiffness or instability~\cite{greydanus2019hamiltonian} unless managed through precise auto-differentiation~\cite{rumelhart1986learning} or meticulous hyperparameter tuning. Finally, there is a clear need for learned models with additional inductive bias tailored to the specific dynamics of soft robots.

% In conclusion, we tackle in this thesis the problem setting of achieving closed-form control of soft robots, ensuring both precise and safe behavior. The key research challenge here is to integrate physical structure into learned models in order to allow exploitation via established PID-like+energy-shaping controllers and stability analysis via Lyapunov arguments.
In conclusion, this thesis addresses the central challenge of achieving closed-form control of soft robots while maintaining accurate and safe operation. The key research goal is to incorporate a physical structure into learned models, thereby enabling the use of PD+energy-shaping-like controllers and allowing for stability verification via Lyapunov-based methods. In the following section, we will pose the principal research question directly connecting to this identified challenge.

